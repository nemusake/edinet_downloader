XBRL入門 Python 学ぶ
EDINETAPIversion2使⽤ Python、Arelleで取得 財務、⾮財務、KAMのデータを取得 株式投資等にも役⽴つ
著 稲垣⼤輔 成⽊涼⾬ 井原侑哉
合同会社オントロジー 編
で
XBRLを 基礎からまるっと
学べる！
Pythonで学ぶ XBRL入門
稲垣大輔、井原侑哉、成木涼雨　著
2024-10-23版 発行
1
はじめに
まずは本書を手にとっていただき、誠にありがとうございます。本書は「初心者のた めの XBRL」をテーマに、XBRLの基礎的な知識から実際にデータを取得する方法を解 説します。また、XBRL から取得したテキストを用いた簡単な分析の例も紹介しており ます。
本書の特徴 本書は、XBRL（eXtensible Business Reporting Launguage）という、財務報告をす
るための国際規格であるコンピュータ言語の取り扱いについて紹介していきます。本書で は、主に有価証券報告書という上場企業の決算書等が掲載された書類を XBRL で取得、 Pythonを用いて分析を行います。また、本書は XBRLを知らない方であっても XBRL がどういった技術で、どのようにしたらデータを取得できるのかということを中心に解説 しております。そのため、初心者に理解しづらい XBRLの仕様などについては適宜省略 しております。 また、プログラミング学習において共通事項にはなりますが、なるべく手を動かして コードを書いてみましょう。手を動かすと格段に学習効果が上がります。 また、本書のサンプルコードは以下リンクに記載しておりますので、適宜参考にしなが ら学習してください。
https://github.com/black76-yy/xbrl_analyze_ontology.git
対象読者 本書の対象読者は、以下のような方を想定しております。
• XBRLについて今は全く知らないけれど、財務情報を用いた分析を行いたい方
• 有価証券報告書等のデータを用いて株式投資に役立てたい方
• XBRLの活用例を知りたい経理人材や公認会計士
2
• 財務情報を用いたテキスト解析を行いたい研究者やエンジニア
• テキスト分析を行うための元ネタを拾いたいエンジニアの方
本書を読み進めるための基礎知識については随所で触れるようにしておりますが、 Pythonなどの基礎知識を持ったうえで学習しておく方がスムーズにコードを動かしやす いかと思います。
参考 本書の参考文献は以下になります。詳しすぎて解説を省略しているものについては、適 宜以下のリンク先などを参考にしながら読み進めて頂けると幸いです。
• 一般社団法人 XBRL JAPAN 「XBRLとは」
• 日本取引所グループ　「適時開示情報の XBRL化」
• 金融庁　「2024年版 EDINETタクソノミの公表について」
• 一般社団法人 XBRL Japan - XBRL Japan Inc. - XBRLとは
• 経営・事業活動を指す。
• EDINET操作ガイド　 EDINET API仕様書 (Version2)
• 「Covid-19パンデミックに関する有価証券報告書「事業等のリスク」の記載の変 化」渡部 美紀子、　 2022年『危険と管理』53巻：p.112-128日本リスクマネジメ ント学会発行 2024年 10月 15日
• Qiita　 XBRL Japan「EDINET APIを利用して、企業情報（XBRLデータ）を 自動で集めてみよう (4/10)」
• Qiita　 XBRLJapan「EDINET開示の XBRLデータ空、平均給与等の従業員情 報を自動で抽出してみよう (5/10)」
• 日本公認会計士協会　監査報告書
• 金融庁　「監査上の主要な検討事項（KAM）の特徴的な事例と記載のポイント」の 公表
• PwC 「KAMの開示に向けてー KAMの基本事項と留意点」
免責事項 本書に記載された内容は、情報の提供のみを目的としています。したがって、本書を用 いた開発、制作、運用は、必ずご自身の責任と判断によって行ってください。これらの情 報による開発、制作、運用の結果については、著者はいかなる責任も負いません。
3
表記関係について 本書に記載されている会社名、製品名などは、一般に各社の登録商標または商標、商品 名です。会社名、製品名については、本文中では©、Ⓡ、™マークなどは表示していま せん。
4
目次
はじめに 2 本書の特徴 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 対象読者 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 参考 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 免責事項 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 表記関係について . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
第 1章 XBRLの基礎知識 8 1.1 本章の目的 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.2 XBRLとは . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.3 XBRLの特徴 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1.4 XBRLのメリット . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 1.5 XBRLの問題点 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 1.6 まとめ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
第 2章 タクソノミと有報 16 2.1 本章の目的 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.2 タクソノミとインスタンス . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.3 有価証券報告書とは . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 2.4 データを取得するために . . . . . . . . . . . . . . . . . . . . . . . . . . 20 2.5 XBRLフォルダの用意 . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 2.6 タクソノミの参照方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 2.7 まとめ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
第 3章 事前準備 29 3.1 本章の目的 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 3.2 EDINET APIを使えるようにしよう . . . . . . . . . . . . . . . . . . . 29
5
目次
3.3 コードエディタを使おう . . . . . . . . . . . . . . . . . . . . . . . . . . 44 3.4 まとめ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
第 4章 たくさんの有報を自動でダウンロードしよう 52 4.1 本章の目的 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 4.2 たくさんの有報のデータを自動でダウンロードしよう . . . . . . . . . . 52 4.3 まとめ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
第 5章 財務諸表から営業利益を自動で取得しよう 60 5.1 本章の目的 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 5.2 1社から取得してみる . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 5.3 タクソノミを確認しよう . . . . . . . . . . . . . . . . . . . . . . . . . . 61 5.4 取得するコードを書こう . . . . . . . . . . . . . . . . . . . . . . . . . . 63 5.5 10社から取得してみる . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 5.6 まとめ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
第 6章 有報からテキストデータを自動で取得しよう 69 6.1 本章の目的 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 6.2 有報から事業等のリスクだけを自動で取得しよう . . . . . . . . . . . . . 69 6.3 まとめ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
第 7章 監査報告書から KAMを自動で取得しよう 73 7.1 本章の目的 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 7.2 監査報告書と KAMについて . . . . . . . . . . . . . . . . . . . . . . . 73 7.3 監査報告書から KAMを自動で取得する . . . . . . . . . . . . . . . . . 77 7.4 まとめ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
第 8章 CSVファイルで出力しよう 84 8.1 本章の目的 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84 8.2 CSVファイルでデータを出力しよう . . . . . . . . . . . . . . . . . . . 85 8.3 まとめ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
第 9章 おわりに 92
付録 A Arelle以外のパーサーの紹介 93
付録 B pathとは何か 94
6
付録 C テキストデータの注意点 95
付録 D コラム：フィルタリングしてダウンロードのできるできない 96
付録 E ライブラリとは何か 98
付録 F 会計基準が違うとなぜ同時にデータ取得ができないの？ 99
付録 G 有価証券報告書以外の書類の集め方 100
著者紹介 102
7
第 1章
XBRLの基礎知識
1.1 本章の目的 XBRLとは財務報告をするための情報を誰もがまとめやすく、拡散しやすく、利用しや すいように国際的に標準化された電子開示に適したコンピュータ言語です。これらは国際 規格であり、各国で投資家は XBRLを用いた意思決定を実施しております。しかし、世 間には XBRLの解説があまり存在しないことから、学習コストが高いのも事実です。そ こで、本章では、そもそも XBRLとはどういったものなのか、XBRLがあることで何が 嬉しいのか、XBRLの注意点について解説をしていきます。
1.2 XBRLとは XBRLとは財務報告をするための情報を「誰もがまとめやすく、拡散しやすく、利用し やすい」ように国際的に標準化された電子開示に適したコンピュータ言語です。
XML *1 というメタ言語をベース作られ、財務情報を記述に特化しています。 名前は「eXtensible Business Reporting Language」の略で、「拡張可能な事業報告言
語」を意味します。 同じ形式でデータ管理することでプログラムでたくさんの企業の情報を一気に取って 来て財務分析を行えたり、毎回 0 から開示書類を作成しなくてよいといった恩恵があり ます。 作成者側のメリットは、作られたフォーマットに企業情報を項目として入力するだけで 簡単に報告書を作成することができることです。利用者側のメリットは、有報であれば EDINETでワンクリックでダウンロードできることです。ダウンロードしたものは様々
*1 様々なデータを記述するために用いるマークアップ言語を開発するためのメタ言語。
8
1.3 XBRLの特徴
な形式に変換できることはとても使いやすいものです。
1.3 XBRLの特徴 XBRLの特徴は、タクソノミとインスタンスの二つによって構成されていることです。 タクソノミとインスタンスを一言で表すと、タクソノミはひな型、インスタンスはその 中身のデータです。
▲図 1.1 タクソノミとインスタンス
1.3.1 タクソノミ タクソノミとは、英語で「Taxonomy」で「分類」という意味し、情報・データなどの 階層構造で整理したものを指します。この要素はをタグと言い、このタグの構造と意味を 定義するものこそがタクソノミといいます。そのため要素ひとつひとつに対して項目（名 称）を定義し紐付けるものがタクソノミといえます。このタグを指定することで、ぱっと 見の名称が異なっていても本質的な意味（タグ）が同じもの同士を比較したり、複数の企 業からその情報を取得することが可能になります。
9
第 1章 XBRLの基礎知識
1.3.2 インスタンス インスタンスとは、英語で「Instance」で「実例」などを意味します。XBRLにおける
インスタンスは、タクソノミで定義したひな型に対し、実際の情報・データそのものを指 します。以下の画像は、タクソノミとインスタンスが記載されているドキュメントの一例 になります。
▲図 1.2 インスタンスのドキュメントの例
タグは<>記号で囲まれている箇所であり、、初めは「<>」、終わりは「</>」とスラッ シュが入ります。この間の要素こそがインスタンスになります。こちらは HTMLなどに 触れたことがある方はイメージしやすいかと思います。 今回であれば、少し見づらいですが、書き始めが頭一つ引っ込んでいる <us-gaap:Rev
enue … decimales=”0></us-gaap:Revenue>がタグです。そして、「200000」がイン スタンス（実際の情報・データ）です。 インスタンスでは数値のデータはもちろん、テキストデータも存在しており、最近では このテキストデータを用いた分析等のニーズも増えています。 例えば公開されている研究だと,
”渡部 美紀子 (2022年)「Covid-19パンデミックに関する有価証券報告書「事業等 のリスク」の記載の変化」、『危険と管理』、53巻、pp.112-128.”
などがあり、「COVID-19が発生してから 2021年３月まで２度の決算を迎えた３月決 算企業の有価証券報告書「事業等のリスク」への記載内容の変化を通して、日本企業の COVID-19に対する情報開示の変遷」（渡部 2022 p.112）についての考察を目的として、 研究がされています。 これらの論文では例えば、『「事業等のリスク」や「ESG項目」などのテキストデータ の変化に応じて「業績」や「株価」の数値にも影響が及ぼされているのではないかを確か める』ような分析が行われています。
10
1.4 XBRLのメリット
1.4 XBRLのメリット XBRL が出てくる前は、財務報告書類は企業ごとに紙媒体で作成されており、企業に とって非常に手間やコストのかかる作業となっていました。さらには紙媒体で作成されて いる情報では二次利用 *2は困難でした。 しかし、現在では XBRLの登場によりこれらのデメリットは解消され、むしろそれら
は以下のようなメリットになりました。 XBRLはタクソノミでタグを指定することにより、
• ひな型に項目（インスタンス）を入力するだけで書類を作成できる作成コストの大 幅カット
• EDINETなどで簡単に様々な形式でダウンロードができる流通の良さ
• タグで情報を紐づけているためファイル形式を変換し二次利用がしやすい
といったことを実現させました。これらを大きく分けて 3者の立場に立って詳しく説明 します。
1.4.1 利用者へのメリット 利用者というのは投資家、アナリスト等、企業の状態を判断するために有価証券報告書 等の書類を閲覧情報利用者を指します。かつては、利用者は開示された資料を見て、手動 で再入力・転記することで情報を集めておりました。これでは時間もかかるのにミスが生 じやすく、確認作業の負担も大きくなってしまいます。このような状況ですと分析どころ ではありません。
*2 情報のファイル形式を変え利用すること。例えば、ネットでの公開、研修用の教材、既存システムで使用 されるがそれぞれ適した形式が異なる。
11
第 1章 XBRLの基礎知識
▲図 1.3 XBRL 登場前の処理
XBRLには整合性チェックの機能があるため、ミスやエラー防止され、情報の品質と透 明性が向上しました。これにより、迅速に情報を加工・分析することが容易となりました。
12
1.4 XBRLのメリット
▲図 1.4 XBRL 登場後の処理
1.4.2 作成者へのメリット 作成者とは、主に上場企業など XBRLを用いて書類を作成する人を指します。例えば、
有価証券報告書を XBRLに手打ちして毎回作成するとなると（時間もお金も）作成コス トが莫大にかかってしまいます。 開示書類は金融庁による EDINET の稼働により、全面 XBRL 化されましたが、印刷 会社のシステムにより作成者自身は XBRLを気にせずに作成することができます。 開示書類の作成支援システムとして、主に宝印刷の X-Smartや、プロネクサスのプロ
ネクサスワークスの 2種類があります。これらを使用することで、Wordのような UIを 用いて数値や文章を入力するだけで、XBRL に対応した書類を作成できるようになりま した。さらに、XBRL の特徴でもあるタグが暗黙的に記録されるため、わざわざ作成者 側がタグ付けを意識することもなく、自動的にタグが付与された XBRL形式でデータが EDINETに展開されることになります。なお、こうした印刷会社の努力により、開示書 類を作っている方でも XBRLの存在を知らないケースも多いのが実情です。これにより、 開示情報としての価値が格段に向上します。
13
第 1章 XBRLの基礎知識
▲図 1.5 出力形式の自動変換
1.4.3 提出機関へのメリット 提出機関とは、主に証券取引所や監督機関などを指します。提出機関は、作成された書 類の整合性チェックなどをする必要がありました。XBRL は整合性チェックの機能があ るため、一部の確認作業を自動化し、業務効率化を図ることができます。機械判別も合わ せて実施することで、制度・信憑性の高い財務情報の取得にもつながります。
1.5 XBRLの問題点 ここまで XBRLのメリットを紹介しました。ですが、デメリットも存在します。 主なデメリットは以下の 3つです。
• 会計基準の違いがある場合は比較できない
• タグの付け方にすべてが依存される
• タクソノミを毎年チェックしなくてはならない
14
1.6 まとめ
1.5.1 会計基準の違いがある場合は一括取得できない 大前提として、会計基準の違いがある場合は、同一の条件で一括で財務データを取得で きません。例えば、JGAAP（日本会計基準）と IFRS（国際会計基準）ではそもそもタグ 自体が異なるものを利用されているため、同じ条件ではデータを抜き出すことが不可能に なってます。例えば、売上高だけでも JGAAPと IFRSではタグが異なるため、JGAAP 用と IFRS用に分けて取得条件を書く必要があります。
1.5.2 タグの付け方にすべてが依存される 企業独自が設定しているタグに関しては共通化されていません。そのため、複数の企業 の情報を取得する際には、タグによってはうまく取得することが出来ないケースがありま す。要因としては、XBRL ファイルの作成自体を印刷会社のシステムに依存しているこ とが一因になります。印刷会社のシステムを利用することで、利用者はタグの付け方を意 識せずに XBRLファイルを作成できてますが、そのせいでタグが正確につけられないこ とがあります。例えば、昨今、注目されている ESGの活動についても 2023年までは政 府が指定しているタクソノミがなかったため、会社独自の拡張タクソノミを指定していま した。その結果、当時は複数の企業が一括で取得することが困難でした。
1.5.3 タクソノミを毎年チェックしなくてはならない タクソノミは毎年変わるものであるため、毎年チェックする必要があります。ESGの
タグのようにほとんどの企業が開示情報に記述する内容であれば、更新され標準タクソノ ミになることもありますが、今後開示項目が追加削除されるにつれて、タクソノミが変更 されるリスクがあります
1.6 まとめ XBRLは財務報告をするための情報を誰もがまとめやすく、拡散しやすく、利用しやす いように標準化されたコンピュータ言語です。統一されたタクソノミのおかげで、財務情 報に関わる利用者、作成者、提出機関のすべてにおいて利便性の向上が見込めます。 次の章では、XBRL の一番の特長であるタクソノミとインスタンスをより詳しく解説
します。
15
第 2章
タクソノミと有報
2.1 本章の目的 XBRL のメリットとして、たくさんのデータから任意のものを自動で取得できること があります。これを行うためには XBRL の特徴を理解する必要があります。本章では、 前章でも少し触れた XBRLの一番の特徴である「タクソノミ」と「インスタンス」につ いて欠点を交え、解説します。 また、情報元である有価証券報告書について知ることで、任意のデータを取得できるよ うになりましょう。
2.2 タクソノミとインスタンス 2.2.1 タクソノミ タクソノミとは、情報・データなどの階層構造で整理したものを指します。この要素を タグと言います。このタグの構造と意味を定義するものこそがタクソノミといいます。要 素ひとつひとつに対して項目（名称）を定義し、紐付けるものがタクソノミというわけ です。 タクソノミには、政府が取り決めた「標準タクソノミ」とその企業独自のタクソノミで ある「提出者別タクソノミ」の 2種類があります。標準タクソノミは政府によって統一さ れています。一方、提出者別タクソノミは企業が独自に指定しているものであり、他の企 業でそのタクソノミで設定されているケースはほぼ無いため、個別対応をしなければなり ません。
16
2.2 タクソノミとインスタンス
2.2.2 インスタンス XBRLにおけるインスタンスは、実際の情報・データそのものを指します。単純に言え ば、インスタンス＝タクソノミの中身です。
2.2.3 タクソノミとインスタンスの欠点 どの技術にもメリットがあればデメリットがあるように XBRL にも欠点があります。
この欠点とは XBRL を利用していく中で避けては通れません。むしろ XBRL 活用はこ れらの欠点と向き合うことに他ならないと私は考えます。 タクソノミとインスタンスの欠点は以下の 3つに集約されます。
• 文章の細かい段落ごとでは抜き出せない
• そもそもタクソノミが指定されていないこともある
• 抜き出す内容を理解しないと抜け出せない
一つずつ見ていきましょう。
文章の細かい段落ごとでは抜き出せない 文章などのテキストデータもタクソノミの中身であるインスタンスにすぎません。イン スタンスはあくまで、タクソノミで指定されたハコの中身です。このハコごと取って来る ことはできても、ハコの中身の一部分だけ取って来ることはできません。つまり、抜き出 せる情報の最小単位は「タクソノミで区切られたもの」ということです。このタクソノ ミで分割されていない文章の細かい段落をそれぞれ分割して抜き出すことはできないの です。 例えば有報の目次では、形が同じであってもタクソノミは大項目についていて小項目も すべて一つのインスタンスとして格納されているため、欲しい情報以外の情報も取れてし まう場合があります。このような場合、情報を取り出した後に、本当に欲しい情報のとこ ろだけを切り抜く作業をしなくてはなりません。これが XBRLを扱う上でつらい箇所に なるでしょう。もしいらない部分などがある場合には、抜き出した後に利用したい形に合 わせてデータ加工をする必要があります。世の中の XBRLユーザーは日々このような泥 臭い作業に向き合っているのです。
17
第 2章タクソノミと有報
タクソノミが指定されていない タクソノミは指定されているが思い通りにいかないという欠点について話しましたが、 もっと根本的な問題がある場合もあります。それは、そもそもタクソノミが指定されてい ないことがあることです。 ごくまれにこのようなケースもあるといった程度ですが、実際に存在します。欲しい情 報のところにタクソノミが指定されていないとそもそも XBRLを用いて情報を抜き出す ことすらできません。これではせっかく標準タクソノミなどで準備がされていても全く意 味がありません。 例えば、2023年度までは ESG *1に関する標準タクソノミが準備されておらず、提出者 別タクソノミを設定していました。そういった状況の中ではタクソノミが設定されず抜け 落ちてしまうケースも実際にありました。また、勘定科目においても同様で、タクソノミ に記載されていないような特殊な勘定科目にはタグがついていないことがあります。
抜き出す内容がわかってないといけない 今度は全く別の角度からの欠点です。情報の取捨選択ができる知見を持たないと上記 2
つの欠点にも気づくことすらできないという点です。いくらタクソノミがきれいに指定し てあっても情報を取ってくる人が取って来る情報そのものについて知らなければ意味があ りません。取って来る情報の対象である有価証券報告書等に関するドメイン知識は必須と 言えるでしょう。また、有報だけ知っていてもタクソノミとインスタンスという概念やタ クソノミの参照方法も知らずには情報は取れません。公認会計士などは有価証券報告書を 読むことに慣れているかもしれませんが、タクソノミとの紐づけが出来ていない人が多い と推測されます。タクソノミのことを勘定科目マスタと考えている人も実は多いです。ど ちらの知識も正確に身に着けることが大事なのです。 そういったわけで、次の章からは調べる対象を有報に絞って、有報についてとタクソノ ミの参照方法について説明しようと思います。
2.3 有価証券報告書とは 有価証券報告書とは、事業年度ごとに企業自ら財務情報や経営状況を外部に開示するた めの資料です。主に事業年度が切り替わってから前年度分の総まとめとして提出されるも のです。基本的に事業内容が変われば、有報の書かれる内容も変わるため、構造自体が変
*1 ESGとは、Environment(環境)、Social(社会)、Governance(ガバナンス（企業統治）)を考慮した投 資活動や経営・事業活動のこと。引用：内閣府ホームページ 2.2_ESGの概要
18
2.3 有価証券報告書とは
わるということもあります。有報を作成する際に目次は決まっていますが、その中の項目 は各企業で変わってくるためこの中から知りたい情報を探すということになってきます。 有報を作成する多くは、印刷会社（宝印刷、プロネクサス）のシステムを用いたうえで、 ASBJ*2 や印刷会社が出している記載要領を等を参照して作ります。そのため、原則的に 記載内容が似ているケースが多いですが、細かいところの書きぶりは変わってきます。 例えば、事業等のリスクの項目は、企業ごとに書き方が変わりやすいところでしょう。 有報の構造は先ほども述べた通り、基本的に事業に左右される節があるため、同じ業界ど ころか同じ企業でも事業年度によっては構造が変わることがあります。 原則的には目次を見ましょう。目次は基本的に記載ルールが決まっているため、大きく ズレることはありません。目次を見て知りたい情報が大体どこに何が書いてあるかという のが確認して、タクソノミとどう紐づいているのかを理解することが XBRL解析には大 切です。
2.3.1 有報の見方 有報は EDINET（エディネット）で誰でも無料で閲覧することが可能です。書類簡易 検索の中の「書類種別」の有価証券報告書にチェックマークを入れ、「提出者／発行者／ ファンド／証券コード」の検索窓で任意の企業の名前を入れ検索することで閲覧できま す。提出期間はデフォルトで 1年となっていますが、全期間 (有報であれば 10年）に伸 ばすこともできます。
*2 正式名称は企業会計基準委員会。日本の会計基準などを作る機関。
19
第 2章タクソノミと有報
▲図 2.1 EDINET のトップページ画面
2.3.2 よく見られる項目 財務情報であれば、「経理の状況」に財務諸表等が記載されています。有報の特徴とし て、テキストデータが豊富ということが挙げられます。テキストデータとはいわゆる文章 での情報です。テキストデータに注目が集まる理由としては、数値だけでは説明しきれな い状況や背景などについて説明できるという点が挙げられます。人はこの文章の情報を読 み取ることができますが、機械にとってはこの文章の意味はわかりませんでした。しか し、自然言語処理技術の発達により、このテキストデータを用いた分析を機械ができるよ うになってきており、テキストデータにより注目が集まっています。 そのほかにも昨今注目されている ESG やコーポレート・ガバナンスなどについての情 報はよく見られる点です。これらは同じ業界・同じ規模感の企業であっても、企業の特色 が出やすく比較がしやすいため投資家などからよく見られる印象があります。数値だけで も区別することはできますが、なぜその数値なのかという背景までわかるとより分析に深 みが出ると思います。この背景を知る項目として文章で構成される「経理の状況」や「事 業等のリスク」などはよく見られる。
2.4 データを取得するために 上記までで何についての情報が欲しいかという目処が立ったら、次はその情報のタクソ ノミを調べましょう。実際に欲しい情報はタクソノミの中のインスタンスですが、そのイ
20
2.5 XBRLフォルダの用意
ンスタンスを取るためにはタクソノミが必要です。知りたい情報から逆算しましょう。 知りたい情報を決め、標準タクソノミなのか提出者別タクソノミなのかを確認しましょ う。標準タクソノミであれば基本的に他の企業でも芋づる式に取って来れます。提出者別 タクソノミであれば、一つ一つ取って来ることになります。 例えば、特別損失の勘定科目などはタクソノミで取れないケースが多いでしょう。なぜ ならば特別損失に記載されている勘定科目は、企業特有のものが設定されている場合があ るためです。例として「プロ野球選手移籍金」などは標準タクソノミに存在しないため、 提出者別タクソノミによって追加され掲載されたことがあります。提出者別タクソノミで は企業ごとに独自のタクソノミが追加されているため、基本的に同じ勘定科目だったとし ても同じタクソノミが設定されていません。
2.5 XBRLフォルダの用意 実際に有報からどのようにしてほしいインスタンスのタクソノミを見つけるのか実践し てみましょう。EDINETにアクセスをして、任意の上場企業を調べ有報をダウンロード します。今回は例として「ANAホールディングス」を用います。まずは、以下のリンク から EDINETへ飛んでください。 ▼ EDINET https://disclosure2.edinet-fsa.go.jp/week0010.aspx そしてサイト内の検索窓から「ANAホールディングス」と検索し、提出書類が「有価 証券報告書」を探します。「XBRL」をクリックしダウンロードします。
21
第 2章タクソノミと有報
▲図 2.2 有報の見方
Windows の方はエクスプローラー、Mac の方は Finder に XBRL フォルダがダウン ロードできているか確認してください。今回は手動で少数のダウンロードを行います。た くさんの情報を元に分析をしたいなど、大量の有報のダウンロードについては次章で取り 扱います。
2.6 タクソノミの参照方法 次に任意のタクソノミの参照方法について解説をします。 2024年 7月現在、タクソノミの参照するなら以下の 3つの方法がわかりやすいです。
• EDINETから CSVファイルをダウンロードして検索
• XBRLファイル内での検索
• 金融庁のタクソノミ要素リストを参照する
本章では以上の 3つの参照方法の概要を説明します。
2.6.1 EDINETから CSVファイルをダウンロードして検索 まずは EDINETから任意の有報をダウンロードする画面で、「CSV」をダウンロード しましょう。
22
2.6 タクソノミの参照方法
▲図 2.3 CSV ファイルのダウンロード
その中から圧縮サイズが一番大きいファイルを開き以下のような表を参照できる状態に してください。
▲図 2.4 タクソノミ CSV
この表は、その有報を構成しているすべてのタクソノミの情報をまとめた表です。特に 以下の 5つについて注目します。
• 「要素 ID」＝ タグ
• 「項目名」＝ 勘定科目や目次など
23
第 2章タクソノミと有報
• 「コンテキスト ID」＝ 期間を示すもの
• 「相対年度」＝コンテキスト IDに対応する期間
• 「連結・個別」＝連結の情報か単体の情報か
コードを用いてデータ取得を行う際、直接必要となって来るのは要素 IDとコンテキス ト IDの 2つです。しかし、人間がそのままその 2つを識別するのは難しいため、他の 3 つを加味し、任意のデータに当てはまる要素 IDとコンテキスト IDを調べます。
2.6.2 XBRLファイル内での検索 データは引き続き ANAの有報を用いて説明します。 (1) ダウンロードした zipファイルを解凍し、開いていく (2) 有報の XBRLフォルダを開く (3) XBRLフォルダの中の PublicDocを開く
▲図 2.5 PublicDocを選択
(4) XBRLファイルを探す（種類のカラムを参照するとわかりやすいです）※ややこし いので注意
24
2.6 タクソノミの参照方法
▲図 2.6 XBRL ファイルを探す
(5) テキストエディターで開く（例：VSCode） ※Wordはダメ（検索できなかったり、どれがタクソノミかわからなかったりする）　 メモや検索エンジンではダメではないが色がついていない分見づらく感じた。
(6) 「Ctrl(Command) + F」で任意の情報を検索（サイドバーの虫眼鏡マークでも検 索可）
25
第 2章タクソノミと有報
▲図 2.7 XBRL ファイル内から項目を検索する
例えば「事業等のリスク」などで検索し、タクソノミを探します。
▲図 2.8 「事業等のリスク」の項目を探す
このような感じで調べたいインスタンスから逆算的にタクソノミを参照することができ
26
2.6 タクソノミの参照方法
ます。 今回の「事業等のリスク」のタクソノミですと、 jpcrp_cor:BusinessRisksTextBlock contextRef="FilingDateInstant”*3
が該当します。
2.6.3 金融庁のタクソノミ要素リストを参照する この手法のメリットは政府が出しているタクソノミの要素に関しては網羅しているとい うことです。ただし、デメリットとして情報量が多いため、慣れていない参照しづらいこ と、提出者別タクソノミについては記載されていないなどが挙げられます。また絶対に正 しいというわけでもなく間違いがあることもあります。よって他の 2つと使い分けて参照 することをオススメします。 では、以下のファイルをダウンロードして実際にタクソノミを調べてみます。 ▼金融庁　タクソノミ要素リスト 1e_ElementList.xlsx 有価証券報告書以外の書類についての情報も載っているため、まずは有報の情報にたど り着くための手順について説明します。 ファイルをダウンロードし開くと、以下のような目次のシートが表示されます。
▲図 2.9 タクソノミ要素リスト
目次から「9 企業内容等の開示に関する内閣府令 第三号様式 有価証券報告書
*3 「contextRef="FilingDateInstant”」は当期の意味。
27
第 2章タクソノミと有報
（jpcrp03000-asr)」のシートに移ります。「詳細ツリー‐標準ラベル（日本語）」（B列）を 対象に知りたい項目を検索します。 「冗長ラベル（日本語）」（C列）で連結と個別を確認するため、連結の「名前空間プレ フィックス」（H列）と「要素名」（I列）を参照します。これをタクソノミとして仕様し ます。 筆者としては、慣れないうち EDINETから CSVファイルをダウンロードして検索す る方法と、XBRL ファイル内での検索を使い分けるのを推奨します。財務データを取得 したい場合には前者。非財務データを取得したい場合には後者を利用するのがやりやすい と思います。 なぜなら、前者では、財務・非財務どちらの情報に対しても取得はできますが、CSVの 内容が必ずしも合っている保証がなく、まれに間違っている場合もあるという大きな欠陥 があるため、後者では、財務情報を取得したい場合に勘定科目を検索してもインスタンス と別の場所に格納されてていることから勘定科目から逆算的にタグを知ることができない ためです。逆に、どれがタグで、どれが context_refで、このタグの意味はこうと理解出 来るようになったら、XBRLフォルダの中の PublicDocを開く方法の情報量にも惑わさ れないと思います。このように一長一短ではあるので場合に分けてデータを取得する方法 を選ぶのを推奨です。
2.7 まとめ 本章では、元情報である有報の XBRLファイルをダウンロードし、インスタンスを抜 き出すためにタクソノミの参照方法やその注意点などについて扱いました。あくまで大事 なことはどのような流れで情報を取得するのかという流れや概念の理解をしていただけれ ば幸いです。今回までで XBRLはどういったもので、どうすれば情報を抜き出すことが できるということが、少しでも思い浮かぶようになれば幸いです。 次の章では、プログラムを利用するための準備を行います。
28
第 3章
事前準備
3.1 本章の目的 本章ではプログラムを使用するために、「プログラミングで利用する EDINET APIの
準備」と「プログラムを動作させるためのソフトウェアの環境構築」について説明します。 もうすでに EDINET APIの利用方法をご存じの方・Pythonが利用可能な状態にある 方は、本章を読み飛ばしていただいて結構です。
3.2 EDINET APIを使えるようにしよう まず、有報をダウンロードするために必須の API*1についてです。 EDINET APIとは、使用者が直接 EDINETのウェブページに行くのではなく、プロ
グラムを介して EDINET のデータベースから効率的にデータを取得できる API です。 EDINET API により、EDINET 利用者は効率的に開示情報を取得することが可能とな ります。 そんな EDINET APIは以下の 2種類です。
• 書類一覧 API
• 書類取得 API
書類一覧 APIは提出された書類を把握するための APIです。こちらは EDINETに提 出された書類の一覧を取得する APIとなっています。書類一覧 APIを用いることで、日 付ごとに分類された提出書類の基本情報を取得出来ます。 書類取得 APIは提出された書類を取得するための APIです。この APIを活用すると、
*1 アプリケーション・プログラミング・インターフェースの略。ソフトウェアやプログラム、Web サービ ス間をつなぐインターフェースのこと。
29
第 3章事前準備
取得書類の種類の指定、ファイル名を企業名にしてダウンロード、フィルタリングした企 業の書類だけダウンロードなどが可能になります。
EDIENT APIの使用には、アカウントの作成と APIキーの発行が必要となります。
3.2.1 注意点 アカウント作成、APIキーの発行にはいくつか注意点があります。この注意点の項目が できていないと、アカウント作成や APIキー発行が出来ないこともあります。 公式の EDINET API 仕様書では Microsoft Edge での利用方法が詳しく記載されて いましたが、Google Chromeでの設定方法の記載がなく利用者も多いと思うので今回は Chromeの説明をします。
Microsoft Edgeご利用の方は以下の URLからダウンロードできる EDINET_API仕 様書を参考にしてください。 ▼ EDINET操作ガイド　 EDINET API仕様書 (Version2) https://disclosure2dl.edinet-fsa.go.jp/guide/static/disclosure/WZEK0110.html
ポップアップの設定 Google Chromeを開き、右上の三点リーダーから「設定」を開きます。
30
3.2 EDINET APIを使えるようにしよう
▲図 3.1 Chrome の設定を開く
画面の左のサイドバーから「プライバシーとセキュリティ」→「サイトの設定」の順で 開きます。
31
第 3章事前準備
▲図 3.2 サイトの設定を開く
次に「ポップアップとリダイレクト」を開きます。
▲図 3.3 ポップアップとリダイレクトを開く
動作のカスタマイズで「ポップアップの送信やリダイレクトの使用を許可するサイト」 を開きます。
32
3.2 EDINET APIを使えるようにしよう
▲図 3.4 ポップアップサイトの追加
「サイトの追加」画面で EDIENT APIのサイトリンク「https://api.edinet-fsa.go.jp」 を入力し、追加します。
▲図 3.5 EDIENT API のサイト URL を追加
これでポップアップの設定は完了です。
33
第 3章事前準備
JavaScriptの設定 再度、Chromeの設定から「プライバシーとセキュリティ」を開きます。
▲図 3.6 プライバシーとセキュリティの設定を開く
次に「V8のセキュリティを管理する」を開きます。
▲図 3.7 V8 オプティマイザーを許可
34
3.2 EDINET APIを使えるようにしよう
「サイトでの V8オプティマイザーの使用を許可する」にチェックを入れてください。 以上で、JavaScriptの設定は完了です。
Cookieの設定 再度、設定画面から「プライバシーとセキュリティの設定」→「サードパーティ Cookie」
の順で開きます。
▲図 3.8 サードパーティ Cookie の設定を開く
「サードパーティ Cookieを許可する」にチェックを入れます。
35
第 3章事前準備
▲図 3.9 サードパーティの Cookie を許可する
以上で Cookieの設定及び Chromeの設定は完了となります。
3.2.2 アカウント作成 アカウントを作成する場合には、以下の URLから、サインイン画面を表示させます。 https://api.edinet-fsa.go.jp/api/auth/index.aspx?mode=1 下の「今すぐサインアップ」からアカウントを作成します。
36
3.2 EDINET APIを使えるようにしよう
▲図 3.10 EDINET API のサインイン画面
サインアップ画面の上のフォームにメールアドレスを入力し、「確認コードを送信」を クリックします。
37
第 3章事前準備
▲図 3.11 メールアドレスを入力し確認コードを受信する
確認コードを入力し、「コードの確認」へ進みます。
38
3.2 EDINET APIを使えるようにしよう
▲図 3.12 確認コードを入力
コードが正しく受理されると確認コード入力欄がなくなります。 次に下段のパスワー ドを設定していきます。 「新しいパスワード」と「新しいパスワードを確認してくださ い」のフォームには同一のパスワードの設定します。パスワードはパスワードポリシーに 沿っていないとエラーが表示されます。
39
第 3章事前準備
▲図 3.13 ユーザーパスワードを入力
パスワードが受理されると、次に多要素認証に移ります。「国コード」と「電話番号」を それぞれ入力したのち、以下のいずれかの多要素認証を行います。
1. SMS による本人確認 SMS にて通知される確認コードを多要素確認コード入力画 面に入力して認証を行う。
2. 自動音声による本人確認 登録した電話番号に発信される自動音声通話を受け取り、 音声ガイドに従い、テンキーで「#」を入力することにより認証を行う。
3. SMSか電話でコードを受け取る。
40
3.2 EDINET APIを使えるようにしよう
▲図 3.14 多要素認証を行う
SMSか電話にて受け取った確認コードを入力すると APIキー発行画面が表示されアカ ウント作成が完了となります。
41
第 3章事前準備
▲図 3.15 多要素認証確認コードを入力
続けて APIキーの発行についてです。多要素認証でのサインイン後に APIキー発行画 面がポップアップ画面で表示されます。 連絡先を入力し、「連絡先登録（Save）」をクリックします。 ※ 2回目以降は以下の画像のように「連絡先変更（Save）」となります。
▲図 3.16 API キー発行画面
確認画面が 2つ表示されるのでどちらも「OK」を押します。
42
3.2 EDINET APIを使えるようにしよう
▲図 3.17 連絡先保存確認画面
▲図 3.18 連絡先保存完了画面
API発行画面に APIキーが表示されます。 この APIキーはコードの中に入れるため、 メモしておいてください。
43
第 3章事前準備
▲図 3.19 API キーを取得
3.3 コードエディタを使おう 次にプログラムを記述し実行する作業場「コードエディタ」の設定をしていきます。
3.3.1 VSCodeを使えるようにしよう コードエディタは様々なものが存在しますが、世の中で広く使われている「VSCode」
というものを使用していきます。では、VSCode のインストール手順を確認していきま しょう。なお、本書ではWindowsでのセットアップを想定しています。
VSCode公式サイトに移動し、インストーラーをダウンロード 以下の URLから「Download for Windows」をクリックしてください。 https://code.visualstudio.com/ 「VSCodeUserSetup-x64-1.94.0.exe」というファイルがダウンロードできれば成功です。
44
3.3 コードエディタを使おう
インストーラーによるセットアップ 先ほどダウンロードした.exeファイルを開いてください。 以下の画像のような画面が出現します。 「同意する」を選択してから「次へ (N)>」をクリックします。
▲図 3.20 VSCode 同意画面
追加の設定画面が表示されます。 全ての項目にチェックをし、「次へ (N)>」をクリックします。
45
第 3章事前準備
▲図 3.21 VSCode インストール時に実行するタスクを選択
今まで選択した項目に間違いがなければ、「インストール (I)」をクリックし、ソフト ウェアのインストールが開始します。
46
3.3 コードエディタを使おう
▲図 3.22 VSCode インストール
ソフトウェア内でのセットアップ インストールされた「VSCode」を開いてください。初期設定では言語が英語になって いるため、日本語に設定を変更します。画面左側にある「拡張機能」を押してください。
47
第 3章事前準備
▲図 3.23 VSCode 拡張機能を追加
検索バーに「japanese」と検索し、一番上に表示される拡張機能を「インストール」を クリックし、日本語化する拡張機能をインストールしましょう。その後、右下に再起動を 促すポップアップが表示されます。「Change Language and Restart」と書かれたボタン から再起動することで、VSCodeの日本語設定が完了します。
48
3.3 コードエディタを使おう
▲図 3.24 VSCode を日本語にする
VSCodeでの Pythonのセットアップ 本書ではプログラミング言語は「Python」を使用します。よって VSCodeで Python が使えるようにセットアップを行いましょう。まずは Python本体のインストールです 以下のサイトから「Python 3.12.3」 の「 Python installer(64-bit)」をダウンロード してください。筆者が現時点でプログラム動作確認済みのバージョンです。以下のリンク を踏むことで直接ダウンロードが行われます。
https://www.python.org/ftp/python/3.12.3/python-3.12.3-amd64.exe 「Python-3.12.3-amd64.exe」というファイルがダウンロードされるので、そのファイ ルを開いてください。以下の画像のような画面が出現します。 必ず「Add python.exe to PATH」にチェックを付けて、「Install Now」をクリックし、
Pythonをダウンロードします。 ※書かれているバージョンは違うものですが、画面は同じものが出てきます。
49
第 3章事前準備
▲図 3.25 Python をインストールする
次に VSCodeでの Pythonの設定を行います。VS Codeを開き、もう一度拡張機能の インストールを行います。検索バーに「python」と入力し、一番上に出てくる拡張機能を インストールしてください。
50
3.4 まとめ
▲図 3.26 VSCode に Python の拡張機能を追加
以上で VSCodeと Pythonの設定は完了です。
3.4 まとめ 以上でプログラミングをするための事前準備が完了しました。プログラミングを利用す ることでより効率的に分析を行うことが可能になります。 次の章では、データを分析するための大量のデータを収集してみます。1カ月単位の大
量の有報を自動で取得できるようになりましょう。
51
第 4章
たくさんの有報を自動でダウンロー ドしよう
4.1 本章の目的 本章では、EDINET APIを用いて、多くの企業のデータを集める方法について解説し ていきます。 前章までで、XBRL データの取得には、XBRL 自体の知識と有価証券報告書の知識 を組み合わせることが必要だと解説しました。また、企業の比較分析などを行うために は、多くの XBRLデータをダウンロードする必要があります。この問題に対してはプロ グラムを用いて自動でデータ取得を行うようにすると有用でしょう。コードについては GitHub上に掲載されておりますが、可能であれば自ら手を動かしてコードを書いてみて みましょう。
4.2 たくさんの有報のデータを自動でダウンロードしよう 4.2.1 ソースコードの中身 まず、完成形のコードが以下になります。
import requests import datetime import os
def make_day_list(start_date , end_date): print("start_date:", start_date) print("end_date:", end_date)
period = end_date - start_date period = int(period.days) day_list = [] for d in range(period + 1):
52
4.2 たくさんの有報のデータを自動でダウンロードしよう
day = start_date + datetime.timedelta(days=d) day_list.append(day)
return day_list
def make_doc_id_list(day_list): securities_report_doc_list = [] for index , day in enumerate(day_list):
url = "https :// disclosure.edinet -fsa.go.jp/api/v2/documents.json" params = {"date": day.strftime("%Y-%m-%d"),
"type": 2, "Subscription -Key":"your_subscription_key" # Subscription -Keyは 自 分 の API キー を 使 用 }
res = requests.get(url , params=params) json_data = res.json() print(day)
if "results" in json_data: for num in range(len(json_data["results"])):
ordinance_code = json_data["results"][num]["ordinanceCode"] form_code = json_data["results"][num]["formCode"] docInfoEditStatus = json_data["results"][num]["docInfoEditStatus"]
if ordinance_code =="010"and form_code =="030000" and docInfoEditStatus !=2:
print(json_data["results"][num]["filerName"], json_data[" results"][num]["docDescription"],
json_data["results"][num]["docID"]) securities_report_doc_list.append(json_data["results"][num]["
docID"])
return securities_report_doc_list
def download_xbrl_in_zip(securities_report_doc_list , number_of_lists): # ▼ ダ ウ ン ロー ド す る 有 報 を 保 存 し て お く 場 所 を 指 定。 も し な け れ ば フォ ル ダ を 作 成 す
る。 save_dir = "/path/to/download/directory/" # あ な た の 保 存 先 の パ ス に 変 更 し て く だ
さ い。 if not os.path.exists(save_dir):
os.makedirs(save_dir)
for index , doc_id in enumerate(securities_report_doc_list): print(doc_id , ":", index + 1, "/", number_of_lists) url =f"https :// disclosure.edinet -fsa.go.jp/api/v2/documents /{ doc_id}" params = {"type": 1,
"Subscription -Key":"your_subscription_key" # Subscription -Keyは 自 分 の API キー を 使 用 }
filename = os.path.join(save_dir , f"{doc_id }.zip") res = requests.get(url , params=params , stream=True)
try : if res.status_code == 200:
with open(filename , 'wb') as file: for chunk in res.iter_content(chunk_size =1024):
file.write(chunk) print(f"Downloaded␣and␣Saved:␣{filename}")
except Exception as e: print(f"Failed␣to␣download␣file␣{doc_id},␣status␣code:␣{e}")
def main(): # ▼ 集 め る 期 間
53
第 4章たくさんの有報を自動でダウンロードしよう
start_date = datetime.date (2024 , 5, 1) # 開 始 日 付 end_date = datetime.date (2024 , 5, 31) # 終 了 日 付 day_list = make_day_list(start_date , end_date)
securities_report_doc_list = make_doc_id_list(day_list) number_of_lists = len(securities_report_doc_list) print("number_of_lists:␣", number_of_lists) print("get_list:␣", securities_report_doc_list)
download_xbrl_in_zip(securities_report_doc_list , number_of_lists) print("download␣finish")
if __name__ == "__main__": main()
4.2.2 実行結果 以下の画像のように 2024/5/1~2024/5/31 までの一カ月間に提出された有報をダウン ロードした結果、今回は 226件の有報が 15分足らずで取得できました。 もっと多くの件数をダウンロードする場合は、サーバーに負荷をかけるためエラー を返されることがあります。一度に取得する期間を絞るか、コード内の関数 down-load_xbrl_in_zipの中に sleep関数などを用いてクールタイムを設けるようにしてみる と良いでしょう。
ターミナル上でのログの一部 start_date: 2024 -05 -01 end_date: 2024 -05 -31 2024 -05 -01 2024 -05 -02 2024 -05 -03 2024 -05 -04 2024 -05 -05 2024 -05 -06 2024 -05 -07 2024 -05 -08 2024 -05 -09 2024 -05 -10 2024 -05 -11 2024 -05 -12 2024 -05 -13 株 式 会 社 あ さ ひ 有 価 証 券 報 告 書－ 第 49期 (2023/02/21－ 2024 /02/20) S100TCYC 2024 -05 -14 2024 -05 -15 株 式 会 社 西 松 屋 チェー ン 有 価 証 券 報 告 書－ 第 68期 (2023/02/21－ 2024 /02/20) S100TF9K 株 式 会 社 オー ク ワ 有 価 証 券 報 告 書－ 第 55期 (2023/02/21－ 2024 /02/20) S100TEV9 2024 -05 -16 株 式 会 社 　 セ キ チュー 有 価 証 券 報 告 書－ 第 73期 (2023/02/21－ 2024 /02/20) S100TG3H 2024 -05 -17 パ レ モ・ ホー ル ディ ン グ ス 株 式 会 社 有 価 証 券 報 告 書－ 第 39期 (2023/02/21－ 2024 /02/20) S100TG6Z 株 式 会 社 フ ジ 有 価 証 券 報 告 書－ 第 57期 (2023/03/01－ 2024 /02/29) S100TGC6 株 式 会 社 　 平 和 堂 有 価 証 券 報 告 書－ 第 67期 (2023/02/21－ 2024 /02/20) S100TGDM 株 式 会 社 瑞 光 有 価 証 券 報 告 書－ 第 61期 (2023/02/21－ 2024 /02/20) S100TGHZ 2024 -05 -18
54
4.2 たくさんの有報のデータを自動でダウンロードしよう
2024 -05 -19 2024 -05 -20 株 式 会 社 サ ン デー 有 価 証 券 報 告 書－ 第 50期 (2023/03/01－ 2024 /02/29) S100TGOR 株 式 会 社 し ま む ら 有 価 証 券 報 告 書－ 第 71期 (2023/02/21－ 2024 /02/20) S100TGLZ 2024 -05 -21 株 式 会 社 Ｎ ａ Ｉ Ｔ Ｏ 有 価 証 券 報 告 書－ 第 73期 (2023/03/01－ 2024 /02/29) S100TGUF 2024 -05 -22 ス ギ ホー ル ディ ン グ ス 株 式 会 社 有 価 証 券 報 告 書－ 第 42期 (2023/03/01－ 2024 /02/29) S100TGZR 株 式 会 社 ニュー テッ ク 有 価 証 券 報 告 書－ 第 42期 (2023/03/01－ 2024 /02/29) S100TH19 株 式 会 社 リ ン ガー ハッ ト 有 価 証 券 報 告 書－ 第 60期 (2023/03/01－ 2024 /02/29) S100TGO1 株 式 会 社 イ オ ン ファ ン タ ジー 有 価 証 券 報 告 書－ 第 28期 (2023/03/01－ 2024 /02/29) S100TH6B 株 式 会 社 ロー ソ ン 有 価 証 券 報 告 書－ 第 49期 (2023/03/01－ 2024 /02/29) S100TH3U 株 式 会 社 エ ディ ア 有 価 証 券 報 告 書－ 第 25期 (2023/03/01－ 2024 /02/29) S100TH85
・ ・
　 (省 略 ) ・ ・
S100TJL9 : 226 / 226 Downloaded and Saved: /path/to/download/directory/S100TJL9.zip Downloaded and Saved: /path/to/download/directory/S100TJL9.zip download finish download finish
ディレクトリでは以下のように書類ごと保存されています。
▲図 4.1 指定したディレクトリに保存を確認
55
第 4章たくさんの有報を自動でダウンロードしよう
実際に分析する際はこの zipファイルを解凍してから使用します。
4.2.3 利用者の環境に合わせて変更が必要なコード (1)日付を指定する
main 関数の中で日付のリストを作成します。 そのリストに入る値を start_date と end_dateで取ってきたい期間を指定します。 あまりに長いとサーバーに負担をかけてしまい、時間がかかるだけでなくエラーになっ てしまう場合もあるため、1ヵ月単位などで取って来ることをオススメします。 また、6 月は前年度の有報の提出期限であるため提出数が特に多く、細かく指定するなどの対処が 必要な月です。 start_date = datetime.date (2024 , 5, 1) # 開 始 日 付 　 随 時 変 更 end_date = datetime.date (2024 , 5, 31) # 終 了 日 付 　 随 時 変 更 day_list = make_day_list(start_date , end_date)
(2)保存先の指定 download_xbrl_in_zip関数の save_dirで保存先の指定をしてください。
def download_xbrl_in_zip(securities_report_doc_list , number_of_lists): # ダ ウ ン ロー ド す る 有 報 を 保 存 し て お く 場 所 を 指 定。 も し な け れ ば フォ ル ダ を 作 成 す
る。 save_dir = "/path/to/download/directory/" # あ な た の 保 存 先 の パ ス に 変 更 し て く だ
さ い。
(3)APIキーの設置 make_doc_id_list 関数と download_xbrl_in_zip 関数の 2 つの関数の中の params
という変数の中で APIキー（Subscription-Key）を先ほど取得した APIキーとして記入 してください。 以下コードでは「””」で囲まれた your_subscription_keyの部分をご自身の APIキー に変更して下さい。 def make_doc_id_list(day_list):
securities_report_doc_list = [] for index , day in enumerate(day_list):
url = "https :// disclosure.edinet -fsa.go.jp/api/v2/documents.json" params = {"date": day.strftime("%Y-%m-%d"),
"type": 2, "Subscription -Key":"your_subscription_key" # Subscription -Keyは 自 分 の API キー を 使 用
}
for index , doc_id in enumerate(securities_report_doc_list): print(doc_id , ":", index + 1, "/", number_of_lists) url =f"https :// disclosure.edinet -fsa.go.jp/api/v2/documents /{ doc_id}" params = {"type": 1,
56
4.2 たくさんの有報のデータを自動でダウンロードしよう
"Subscription -Key":"your_subscription_key" }
# Subscription -Keyは 自 分 の API キー を 使 用
4.2.4 解説 コードの中身について解説をしていきます。
書類を取得してくる関数 make_doc_id_list 関数では、各日付について EDINET API を呼び出し、有報の固
有番号であるドキュメント IDを収集します。EDINET APIを呼び出す際に APIキーが 必要となるため、取得してもらいました。paramsの”type”は取得情報の指定をしてお り、２は提出一覧およびメタデータの取得を指します。これにより、後続の処理で有価証 券報告書を特定できます。また、途中で指定している ordinance_codeと form_codeは それぞれ府令コードと様式コードを指すものであり、今回は有価証券報告書を取得したい ため、以下のように指定をしております。
• ordinance_code=010,
• form_code=30000
docInfoEditStatus は書類情報修正区分を示すものであり、財務局員が書類を修正 した場合に修正前の書類にはこの書類情報修正区分の数値に 2 が割り当てられます。 最新の書類を取得したいため docInfoEditStatus !=2 で修正前の書類を取得せずに処 理を行うようにしています。該当した提出書類の DocID（書類管理番号）を取得し、 securities_report_doc_list（有報のリスト）に格納します。 def make_doc_id_list(day_list):
securities_report_doc_list = [] for index , day in enumerate(day_list):
url = "https :// disclosure.edinet -fsa.go.jp/api/v2/documents.json" params = {"date": day.strftime("%Y-%m-%d"), "type": 2, "Subscription -Key":
"your_subscription_key"} res = requests.get(url , params=params) json_data = res.json()
if "results" in json_data: for num in range(len(json_data["results"])):
ordinance_code = json_data["results"][num]["ordinanceCode"] form_code = json_data["results"][num]["formCode"] docInfoEditStatus = json_data["results"][num]["docInfoEditStatus"]
if ordinance_code =="010"and form_code =="030000" and docInfoEditStatus !=2:
print(json_data["results"][num]["filerName"], json_data[" results"][num]["docDescription"],
json_data["results"][num]["docID"]) securities_report_doc_list.append(json_data["results"][num]["
docID"])
57
第 4章たくさんの有報を自動でダウンロードしよう
return securities_report_doc_list
ZIP形式でダウンロードする関数 download_xbrl_in_zip関数では各ドキュメント IDについて APIを呼び出し XBRL
ファイルを ZIP形式で指定された場所にダウンロードします。 paramsの”type”は取 得情報の指定をしており、１はメタデータのみを取得するものです。つまり、提出された 書類の本文と監査報告書を取得することができます。resのステータスコードが 200はリ クエスト成功を意味し、成功したもののみ XBRL ファイルをダウンロードしています。 このダウンロード時に各ファイルは ZIP形式で保存され、ファイル名はドキュメント ID になります。 def download_xbrl_in_zip(securities_report_doc_list , number_of_lists):
# ▼ ダ ウ ン ロー ド す る 有 報 を 保 存 し て お く 場 所 を 指 定。 も し な け れ ば フォ ル ダ を 作 成 す る。
save_dir = "/path/to/download/directory/"# あ な た の 保 存 先 の パ ス に 変 更 し て く だ さ い。
if not os.path.exists(save_dir): os.makedirs(save_dir)
for index , doc_id in enumerate(securities_report_doc_list): url = f"https :// disclosure.edinet -fsa.go.jp/api/v2/documents /{ doc_id}" params = {"type": 1, "Subscription -Key":"your_subscription_key"} filename = os.path.join(save_dir , f"{doc_id }.zip") res = requests.get(url , params=params , stream=True)
try : if res.status_code == 200:
with open(filename , 'wb') as file: for chunk in res.iter_content(chunk_size =1024):
file.write(chunk) print(f"Downloaded␣and␣Saved:␣{filename}")
except Exception as e: print(f"Failed␣to␣download␣file␣{doc_id},␣status␣code:␣{e}")
以上がコードの解説になります。 ダウンロードしたファイルが有報のドキュメント IDでラベリングされています。しか
し、これではファイルをいちいち開かないとどの企業のものかわかりません。そのような 場合は、書類一覧 APIで企業名を取得しファイルを保存する際、企業名で保存できるよ うプログラムを変更するのも有効でしょう。
4.3 まとめ 本章では、一度に大量のデータをダウンロードすることについて解説しました。毎回
EDINETからダウンロードして中身を確認する手間が省けるため、プログラムを回す方 が圧倒的に楽だと思います。 もし興味があれば、このコードを使いやすく改良してみて ください。コードは GitHubにも置いてあります。
58
4.3 まとめ
さて次章からこのデータを使用して、ついにデータ分析をしていこうと思います。
59
第 5章
財務諸表から営業利益を自動で取得 しよう
5.1 本章の目的 前章までで分析に必要な対象である書類の取得方法を学習しました。本章からは、実際 に有報の中からデータを取得をしていきます。今回は、売上高・費用、資産、負債といっ た財務データを XBRL ファイルから取得していきます。財務データを活用することで、 投資意思決定に役立つことがありますので、ぜひとも活用してください。
5.2 1社から取得してみる 財務データを取得する際には、以下に気をつける必要があります。
• 適用される会計基準は何なのか
• 連結財務諸表からデータを取得するか、単体財務諸表からデータを取得するか
• 勘定科目は揃っているか
上記の 3項目が統一されていないと、同じコードでデータを取得することは困難になり ます。それらの対応のためにコードの条件分岐を実施したりするなど、XBRL を利用す る際の苦労はこちらに集約されています。 今回はトヨタ自動車株式会社を例に、データの取得を試みようと思います。トヨタ自動 車株式会社の分析において、連結財務諸表からデータを抜き出そうと考えた所、適用され る会計基準は国際会計基準 (IFRS)でした。したがって、国際会計基準 (IFRS)を適用し ている連結財務諸表の営業利益を取得するためのコードを書くことを決めました。 一度に何社も取得するとコードのどの部分でデータを取得しているのかが理解がしづら
60
5.3 タクソノミを確認しよう
いため、トヨタ自動車 1社から営業利益のデータを抜き出し、データ取得の必要最低限に ついて学んでいきましょう。
5.3 タクソノミを確認しよう データを取得するにあたってタクソノミを指定します。財務データの取得には「タクソ ノミのタグ」と「コンテキスト IDという期間などを表す指標」の 2つ指定が必要です。 このタクソノミを参照する方法については主に 2章に記載しているため参考にしてくださ い。本章ではそこで紹介した 1 つ目の「EDINET から CSV ファイルをダウンロードし て検索」を用いてタクソノミを参照します。EDINETから有報をダウンロードする画面 で「CSV」をクリックし、その有報の CSVファイルをダウンロードします。その中の圧 縮サイズが一番大きいファイルを開くと以下のような表が出てきます。
▲図 5.1 csv データ
この表は、その企業で利用されているタクソノミをまとめたもので、標準タクソノミな らび提出者タクソノミも掲載されています。特に重要な項目は以下のとおりです。
• 「要素 ID」＝ タグ
• 「項目名」＝ タグが示す勘定科目や目次など
• 「コンテキスト ID」＝ コードの context_refに対応するもの、期間や連結・個別を 表すもの
• 「相対年度」＝コンテキスト IDに対応する期間
• 「連結・個別」＝子会社も合わせたグループ会社全体のものかその企業の個別のも
61
第 5章財務諸表から営業利益を自動で取得しよう
のか
コード的には要素 IDとコンテキスト IDがわかればデータの取得が可能となりますが、 それだけを見ても内容が人間には判別しづらいため、他の 3つのカラムを参照し正しい要 素 IDとコンテキスト IDを見極めます。 では項目名が営業利益である行を探しましょう。項目名を指定して検索をしないと、別 の列にはいっている営業利益という単語も拾ってしまうため、ここは留意が必要です。
▲図 5.2 csv データ
今回の取得条件は「国際会計基準 (IFRS)で作成された連結の財務諸表」のため、項目 名にも（IFRS）と書かれています。タグの中にはこの会計基準の情報も含まれて細かく 区別されています。会計基準が変わると当然比較ができないようにそもそもデータの取得 もできないため覚えておきましょう。 以上のようにタクソノミを調べると、要素 IDが”jpigp_cor:OperatingProfitLossIFRS”、 コンテキスト IDが”CurrentYearDuration”*1と特定できました。 ただし、要素 IDのみ使用するのは「：」以降の「OperatingProfitLossIFRS」の部分
のみとなります。 このタクソノミは次のコーディングの部分で使用するのでメモをしておいてください。
*1 期間を表すコンテキスト IDが何を指すのかについては表の右隣の相対年度の列を参照してください。要 素名、項目名が全く同じであってもこのコンテキスト IDが違うと年度が違うということです。多くの場 合、最新の情報を求めるため、「当期」を取得することが多いと思います。また、連結・個別の区別もコ ンテキスト IDで区別することがあるので注意して下さい。
62
5.4 取得するコードを書こう
5.4 取得するコードを書こう 本書では、XBRLを読み取るために Arelleという OSS(オープンソースソフトウェア)
を利用します。Arelle は XBRL の中身を検証するためのものです。Python のライブラ リとしての機能もあり、無料で使用することができるため選びました。 まず XBRLの中身を覗くために Arelleが利用可能な環境にしましょう。ターミナル上
で以下を実行し、インストールをしてください。 pip install arelle -release
こちらで Arelleが利用可能になります。 続いてコードを細かく分けて解説していきます。 まず有報の中から今回取得する項目を抜き出す準備をしています。今回であれば、営業 利益の他に「EDINETCODE」「企業名」を取得し、企業ごとに営業利益が確認できるよ うにします。 また、取得したデータを入れるための箱を作ります。
def make_edinet_company_info_list(xbrl_file): edinet_company_info_list = [] company_data = {
"EDINETCODE": "", "企 業 名 ": "", "営 業 利 益 (IFRS)": "",
}
Arelle を使用するためにコントローラーを初期化し、modelMager.load(xbrl_file) で XBRLデータを読み込みます。 ctrl = Cntlr.Cntlr() model_manager = ModelManager.initialize(ctrl)
model_xbrl = model_manager.load(xbrl_file)
具体的な取得したい情報を取得していきます。 for文で読み込んだデータに対し、「.concept.qname.localName =」でタグを指定する
ことにより factに望んだ実データを入れるようにループ処理をします。 該当したものは「fact.value」で取得できるようになっています。 注意点として、Arelleではタグの指定をするときには先ほど調べたものを丸々コピペす るとデータの取得ができません。「：」以降の「OperatingProfitLossIFRS」と指定する ことでデータの取得が行えます。 また、二重で if文を書き、「contextID = 」でコンテキスト IDを指定することにより 期間なども指定し情報を一つに絞ることができます。
63
第 5章財務諸表から営業利益を自動で取得しよう
財務データの多くは当期だけではなく前期なども記載があり任意のデータを絞り込めな い、もしくは間違う可能性があるため必ず指定しましょう。 最後に取得したインスタンスを先ほど作成したリストに入れます。
# 実 デー タ を 探 し て 取 得 for fact in model_xbrl.facts:
# EDINET コー ド を 探 す if fact.concept.qname.localName == 'EDINETCodeDEI ':
company_data["EDINETCODE"] = fact.value print("EDIENT コー ド ␣： ", fact.value)
# 企 業 名 を 探 す elif fact.concept.qname.localName == 'FilerNameInJapaneseDEI ':
company_data["企 業 名 "] = fact.value print("企 業 名 ␣： ", fact.value)
# 営 業 利 益 (IFRS)を 探 す elif fact.concept.qname.localName == 'OperatingProfitLossIFRS ': # タ グ は
「：」 以 降 の 部 分 を 指 定 if fact.contextID == 'CurrentYearDuration ' and company_data["営 業 利 益 (
IFRS)"] == "": company_data["営 業 利 益 (IFRS)"] = fact.value print("営 業 利 益 (IFRS)： ", fact.value)
# 見 つ け た デー タ を リ ス ト に 入 れ る edinet_company_info_list.append ([
company_data["EDINETCODE"], company_data["企 業 名 "], company_data["営 業 利 益 (IFRS)"],
])
return edinet_company_info_list
ここまでの処理を行う XBRLファイルをパスで指定します。 パスとはファイルなどの居場所を示すものであり、VS Codeで目的のファイルを右ク リックすることで「パスをコピー」と出てくるためそのままコピペしましょう。（相対パ スでも可）また、ターミナル上で結果を確認できるように print文を記述します。 def main():
# 各 人 の XBRL ファ イ ル の パ ス (た だ コ ピー し て も 動 き ま せ ん ) xbrl_file = r"\xxx\ ファ イ ル 名 \XBRL\PublicDoc\XBRL ファ イ ル 名 .xbrl"
company_info = make_edinet_company_info_list(xbrl_file) for info in company_info:
print(info)
これらをまとめると以下のようになり、データを取得できるはずです。 from arelle import ModelManager from arelle import Cntlr import os import glob
def make_edinet_company_info_list(xbrl_file): edinet_company_info_list = [] company_data = {
"EDINETCODE": "", "企 業 名 ": "",
64
5.5 10社から取得してみる
"営 業 利 益 (IFRS)": "", }
ctrl = Cntlr.Cntlr() model_manager = ModelManager.initialize(ctrl)
model_xbrl = model_manager.load(xbrl_file)
# 実 デー タ を 探 し て 取 得 for fact in model_xbrl.facts:
# EDINET コー ド を 探 す if fact.concept.qname.localName == 'EDINETCodeDEI ':
company_data["EDINETCODE"] = fact.value
# 企 業 名 を 探 す elif fact.concept.qname.localName == 'FilerNameInJapaneseDEI ':
company_data["企 業 名 "] = fact.value
# 営 業 利 益 (IFRS)を 探 す elif fact.concept.qname.localName == 'OperatingProfitLossIFRS ': # タ グ は
「：」 以 降 の 部 分 を 指 定 if fact.contextID == 'CurrentYearDuration ':
company_data["営 業 利 益 (IFRS)"] = fact.value
# 見 つ け た デー タ を リ ス ト に 入 れ る edinet_company_info_list.append ([
company_data["EDINETCODE"], company_data["企 業 名 "], company_data["営 業 利 益 (IFRS)"],
])
return edinet_company_info_list
def main(): # 各 人 の XBRL ファ イ ル の パ ス (た だ コ ピー し て も 動 き ま せ ん ) xbrl_file = r"\xxx\ フォ ル ダ 名 \XBRL\PublicDoc\XBRL ファ イ ル 名 .xbrl"
company_info = make_edinet_company_info_list(xbrl_file) for info in company_info:
print(info)
print("extract␣finish")
if __name__ == "__main__": main()
これにより、以下のようにトヨタのデータを取得することができました。
営 業 利 益 (IFRS)： 5352934000000 EDIENT コー ド ： E02144 企 業 名 ： ト ヨ タ 自 動 車 株 式 会 社 ['E02144 ', 'ト ヨ タ 自 動 車 株 式 会 社 ', '5352934000000 '] extract finish
5.5 10社から取得してみる ここからはより実用的にしていくために今学んだ自動でデータを取得する技術を複数社 の書類に対して行います。
65
第 5章財務諸表から営業利益を自動で取得しよう
今回は、トヨタ自動車株式会社に追加して、国際会計基準 (IFRS)で連結財務諸表を使 用している、営業利益が記載されている企業が対象になります。 以上の条件に合う企業を 10社ピックアップしました。
• キッコーマン株式会社
• 東レ株式会社
• パナソニックホールディングス株式会社
• トヨタ自動車株式会社
• 日鉄ソリューションズ株式会社
• 株式会社ディー・エヌ・エー
• サッポロホールディングス株式会社
• ソニーグループ株式会社
• アサヒグループホールディングス株式会社
• キリンホールディングス株式会社
EDINET から以上の 10 社を検索し XBRL のボタンをクリックすることで手動で XBRLファイルをダウンロードすることができます。 先ほどのコードと異なる点は「ファイルパスを 1社から 10社に増やすこと」と「それ ぞれの企業に対して自動でデータを取得し、次の企業に移り同じ処理を行うこと」の 2つ です。 from arelle import ModelManager from arelle import Cntlr import os import glob
def make_edinet_company_info_list(xbrl_files): edinet_company_info_list = [] for index , xbrl_file in enumerate(xbrl_files):
company_data = { "EDINETCODE": "", "企 業 名 ": "", "営 業 利 益 (IFRS)": "",
}
ctrl = Cntlr.Cntlr() model_manager = ModelManager.initialize(ctrl)
model_xbrl = model_manager.load(xbrl_file) print("XBRL ファ イ ル を 読 み 込 ん で い ま す ", ":", index + 1, "/", len(
xbrl_files))
# 実 デー タ を 探 し て 取 得 for fact in model_xbrl.facts:
# EDINET コー ド を 探 す if fact.concept.qname.localName == 'EDINETCodeDEI ':
company_data["EDINETCODE"] = fact.value
# 企 業 名 を 探 す elif fact.concept.qname.localName == 'FilerNameInJapaneseDEI ':
66
5.5 10社から取得してみる
company_data["企 業 名 "] = fact.value
# 営 業 利 益 (IFRS)を 探 す elif fact.concept.qname.localName == 'OperatingProfitLossIFRS ': # タ グ
は 「：」 以 降 の 部 分 を 指 定 if fact.contextID == 'CurrentYearDuration ':
company_data["営 業 利 益 (IFRS)"] = fact.value
# 見 つ け た デー タ を リ ス ト に 入 れ る edinet_company_info_list.append ([
company_data["EDINETCODE"], company_data["企 業 名 "], company_data["営 業 利 益 (IFRS)"],
])
return edinet_company_info_list
def main(): # 各 人 の XBRL ファ イ ル の パ ス (た だ コ ピー し て も 動 き ま せ ん )
xbrl_files = glob.glob(r'* フォ ル ダ 名 \*\ XBRL\PublicDoc \*. xbrl')
company_info = make_edinet_company_info_list(xbrl_files) for info in company_info:
print(info)
print("extract␣finish")
if __name__ == "__main__": main()
▼結果 XBRL ファ イ ル を 読 み 込 ん で い ま す : 1 / 10 XBRL ファ イ ル を 読 み 込 ん で い ま す : 2 / 10 XBRL ファ イ ル を 読 み 込 ん で い ま す : 3 / 10 XBRL ファ イ ル を 読 み 込 ん で い ま す : 4 / 10 XBRL ファ イ ル を 読 み 込 ん で い ま す : 5 / 10 XBRL ファ イ ル を 読 み 込 ん で い ま す : 6 / 10 XBRL ファ イ ル を 読 み 込 ん で い ま す : 7 / 10 XBRL ファ イ ル を 読 み 込 ん で い ま す : 8 / 10 XBRL ファ イ ル を 読 み 込 ん で い ま す : 9 / 10 XBRL ファ イ ル を 読 み 込 ん で い ま す : 10 / 10 ['E00435 ', 'キッ コー マ ン 株 式 会 社 ', '66733000000 '] ['E00873 ', '東 レ 株 式 会 社 ', '57651000000 '] ['E01772 ', 'パ ナ ソ ニッ ク ホー ル ディ ン グ ス 株 式 会 社 ', '360962000000 '] ['E02144 ', 'ト ヨ タ 自 動 車 株 式 会 社 ', '5352934000000 '] ['E05304 ', '日 鉄 ソ リュー ショ ン ズ 株 式 会 社 ', '35001000000 '] ['E05460 ', '株 式 会 社 デ ィ ー ・ エ ヌ・ エー ', ' -28270000000 '] ['E00393 ', 'サッ ポ ロ ホー ル ディ ン グ ス 株 式 会 社 ', '11820000000 '] ['E01777 ', 'ソ ニー グ ルー プ 株 式 会 社 ', '1208831000000 '] ['E00394 ', 'ア サ ヒ グ ルー プ ホー ル ディ ン グ ス 株 式 会 社 ', '244999000000 '] ['E00395 ', 'キ リ ン ホー ル ディ ン グ ス 株 式 会 社 ', '150294000000 '] extract finish
基本的には先ほどと同じことをしておりますので、ここではコードを変えた箇所につい て確認していきましょう。 対象企業が増えたため同じ処理をすべての XBRLファイルで行うために for文でルー
プ処理を行います。 また、長時間になる場合もありますので print文で全体で何社分行うのか、現在どのあ
67
第 5章財務諸表から営業利益を自動で取得しよう
たりの処理をしているのかというのが確認できるようにしてあります。 for index , xbrl_file in enumerate(xbrl_files):
　 　 　 　 　・ 　 　 　 （省 略） 　 　 　 　 　 ・ print("XBRL ファ イ ル を 読 み 込 ん で い ま す ", ":", index + 1, "/", len(
xbrl_files))
main()関数のところでは、先ほど同様に対象の XBRLファイルのパスを指定する必要 があります。1社ずつパスを書いても正常に動くのですが、対象のファイルが増えるほど 面倒であるため、正規表現を使用しています。 正規表現とは、直接パスを通したものだけに処理をするのではなく「パターンに一致す るものすべて」に処理をするためのものです。glob モジュールはそういった時に使用さ れ、「ｒ」の中のクオーテーションの中がそのパターンの型になっています。また「＊」は どんな文でも、何文字でも入れることができるという意味を持ちます。そのため、ここが 固有値に当たる部分を指定するとうまくいきます。 パスはそのファイルの居場所であるため環境により異なります。そのため、同じ通りに コード書いてもパスが異なっているとうまく動作しません。対象ファイルが過不足なく指 定できるように気を付けて書くようにしてください。 xbrl_files = glob.glob(r'* フォ ル ダ 名 \*\ XBRL\PublicDoc \*. xbrl')
5.6 まとめ この章では、XBRL を使用して有価証券報告書から、企業の EDINET コードと企業
名、そして財務情報である営業利益を取得しました。財務データを取得できるようになる と、同じ業種などで企業を比較などがしやすくなります。財務データは XBRLファイル を直接見てもタグが見つけられないことが少しネックですが、正しく指定してあげればか なり有効に使えるでしょう。その一方で、会計基準の違いなどによりタグが異なると一気 に取得することもできないため、そのような会計のドメイン知識も必要になってきます。 また、XBRLのタグは正しく付与されていないことも時々あり、そのせいでデータが上手 く取得できないと嘆く人も多いです。多くの XBRL ユーザーが XBRL に苦労するとこ ろがタグなのです。このタグの操作は実際にやってみないとわからない点が多いので、苦 しみながら学習していきましょう。 次章では非財務情報であるテキストデータを取得していきます。
68
第 6章
有報からテキストデータを自動で取 得しよう
6.1 本章の目的 本章では有価証券報告書からテキストデータを取得してみます。有価証券報告書は財務 諸表に代表される財務データのみならず、現在の事業の状況や財務データが算出された背 景などについて書かれたテキストデータがあります。こうしたことから、多くの研究者が 有価証券報告書を用いたテキスト分析を実施しております。さらに、昨今の AIの発展な どによりテキストデータの解析技術が向上し注目が高まっています。
6.2 有報から事業等のリスクだけを自動で取得しよう 今回取得するテキストデータの項目は、事業等のリスクと呼ばれる項目です。事業等の リスクには、企業の財政状態や経営状況及びキャッシュ・フローの状況等に重要な影響を 与える可能性があると経営者が認識している主要なリスクについて記載がされています。 企業ごとはもちろん、事業年度ごとにも記載内容が大きく変わることもある項目です。そ のため注目度も高く、テキスト分析などがされやすい項目と言えます。 本章でも前章同様にトヨタ自動車株式会社を軸にした 10 社からデータの取得を試み
ます。
6.2.1 タクソノミを確認しよう 本章でも、前までと同様にタクソノミを確認することから始めます。 本章では、「XBRLファイル内で検索」でタクソノミを参照します。コードエディタ (本
69
第 6章有報からテキストデータを自動で取得しよう
書では VS Code)で直接 XBRLファイルを開き、「Ctrl+F」で事業等のリスクを検索し ます テキストデータは財務データと異なり、XBRL ファイル内で直接タグで囲まれて記述
されているため、実際に検索にかけてタクソノミを調べることができます。 検索をかけ、ハイライトされている前後を確認すると以下のような部分が見つかると思 います。 <jpcrp_cor:BusinessRisksTextBlock contextRef="FilingDateInstant">&lt;p style="page -break -before:always;␣line -height :0.75pt;␣width :100%;␣font -size :0.75pt;"&gt; &lt;/ p&gt; &lt;h3 class="smt_head2" style="font -family :&amp;apos;MS␣ゴ シッ ク &amp;apos;;"&gt;3 【事 業 等 の リ ス ク】 ～ （省 略）
この"jpcrp_cor:BusinessRisksTextBlock”がタグであり、"FilingDateInstant"がコン テキスト IDとなります。
6.2.2 取得するコードを書こう 大まかなコードの形は前章のものと変わりません。 取得する対象が財務データである「営業利益 (IFRS)」からテキストデータである「事
業等のリスク」に代わっているため、タクソノミを変える必要があります。 タクソノミを先ほど調べた以下のものに書き変えましょう。 タグ（要素 ID）が”BusinessRisksTextBlock”、コンテキスト IDが”FilingDateInstant” タグの方はタクソノミを調べたもののうち「:」以降の「BusinessRiskTextBlock」のみ を指定します。 if fact.concept.qname.localName == 'BusinessRisksTextBlock ':
if fact.contextID == 'FilingDateInstant ': company_data["事 業 等 の リ ス ク "] = fact.value
今回は BeautifulSoupというライブラリと reモジュールの両方を使用してデータを綺 麗にしています。2つを使用することでより綺麗な状態でデータを取得できます。
Web 上の文章は綺麗に見せるための HTML タグという機械への命令がテキストデー タに混在し、人間には読みづらいものとなっています。BeautifulSoupはこれを除去する 役割を担っています。
reモジュールは書類ごとで空白や改行の量が違うこともあるため、データを集める時点 で全て除去し統一する役割を担っています。 これらどちらか片方のみを使用しても似たようなことはできます。しかし、Beautiful-
Soupだけだと空白や改行がたくさん残ってしまう、reモジュールだけではBeautifulSoup ほど高精度でタグやネストを処理できないといった問題が残ってしまいます。両者のライ ブラリを利用することで双方の弱点を補完し、綺麗に文章を取得することが可能になり
70
6.2 有報から事業等のリスクだけを自動で取得しよう
ます。 # BeautifulSoupを 使っ て HTMLタ グ を 除 去 soup = BeautifulSoup(company_data["事 業 等 の リ ス ク "], "html.parser") company_data["事 業 等 の リ ス ク "] = soup.get_text ()
# 空 白 や 改 行 を 取 り 除 く company_data["事 業 等 の リ ス ク "] = re.sub(r'\s', '', company_data["事 業 等 の リ ス ク "]) .strip()
▼ソースコード from arelle import ModelManager from arelle import Cntlr import os import glob import re from bs4 import BeautifulSoup
def make_edinet_company_info_list(xbrl_files): edinet_company_info_list = [] for index , xbrl_file in enumerate(xbrl_files):
company_data = { "EDINETCODE": "", "企 業 名 ": "", "事 業 等 の リ ス ク ": "",
}
ctrl = Cntlr.Cntlr() model_manager = ModelManager.initialize(ctrl)
model_xbrl = model_manager.load(xbrl_file) print("XBRL ファ イ ル を 読 み 込 ん で い ま す ", ":", index + 1, "/", len(
xbrl_files))
# 実 デー タ を 探 し て 取 得 for fact in model_xbrl.facts:
# EDINET コー ド を 探 す if fact.concept.qname.localName == 'EDINETCodeDEI ':
company_data["EDINETCODE"] = fact.value
# 企 業 名 を 探 す elif fact.concept.qname.localName == 'FilerNameInJapaneseDEI ':
company_data["企 業 名 "] = fact.value
# 事 業 等 の リ ス ク を 探 す elif fact.concept.qname.localName == 'BusinessRisksTextBlock ': # タ グ
は 「：」 以 降 の 部 分 を 指 定 if fact.contextID == 'FilingDateInstant ':
company_data["事 業 等 の リ ス ク "] = fact.value
# BeautifulSoupを 使っ て HTMLタ グ を 除 去 soup = BeautifulSoup(company_data["事 業 等 の リ ス ク "], "html.
parser") company_data["事 業 等 の リ ス ク "] = soup.get_text ()
# 空 白 や 改 行 を 取 り 除 く company_data["事 業 等 の リ ス ク "] = re.sub(r'\s', '',
company_data["事 業 等 の リ ス ク "]).strip()
# 見 つ け た デー タ を リ ス ト に 入 れ る edinet_company_info_list.append ([
company_data["EDINETCODE"], company_data["企 業 名 "], company_data["事 業 等 の リ ス ク "],
71
第 6章有報からテキストデータを自動で取得しよう
])
return edinet_company_info_list
def main(): # 各 人 の XBRL ファ イ ル の パ ス (た だ コ ピー し て も 動 き ま せ ん ) xbrl_files = glob.glob(r'*xbrl_zip \*\ XBRL\PublicDoc \*. xbrl')
company_info = make_edinet_company_info_list(xbrl_files) for info in company_info:
print(info)
print("extract␣finish")
if __name__ == "__main__": main()
6.3 まとめ 本章はテキストデータの取得について学びました。取得した事業等のリスクは有価証券 報告書の中でも目にしやすい項目の 1 つでもある項目です。このように欲しいテキスト データのみを取得できると企業の比較や分析など様々な用途で便利に使用することができ ます。 次章は、有価証券報告書の提出本文書ではなく監査報告書という追加の書類から「監査 上の主要な検討事項（KAM）」という項目を抽出します。
72
第 7章
監査報告書から KAMを自動で取得 しよう
7.1 本章の目的 本章では今までと少し異なり、有価証券報告書の添付書類である監査報告書という書類 からデータを取得します。 具体的には KAMという指標を取得します。KAMは「当年度の財務諸表の監査におい
て、監査人が職業的専門家として特に重要であると判断した事項」です。しかし、KAM は会計士などでない限りあまり知られていないものです。本章では、監査報告書と KAM が何かを説明したうえでデータを取得できるようなることを目指します。
7.2 監査報告書と KAMについて KAMとは「当年度の財務諸表の監査において、監査人が職業的専門家として特に重要 であると判断した事項」をまとめた項目であり、監査報告書はこの KAMや監査人の名前 など監査に関わる事項が記載されている書類です。 監査をする会計士以外の多くの人は監査報告書や KAM がわからない方も多いと思い ます。この 2つについてもう少し詳しく知った上でデータを取得しましょう。
7.2.1 監査報告書とは 監査報告書は日本会計士協会によると以下のような書類だと定められています。
経営者の作成した財務諸表が、一般に公正妥当と認められる企業会計の基準に準拠 して、企業の財政状態、経営成績及びキャッシュ・フローの状況をすべての重要な
73
第 7章監査報告書から KAMを自動で取得しよう
点において適正に表示しているかどうかについて監査人の監査意見を述べた報告書 である。出典：日本会計士協会 監査報告書
簡単に言うと、「財務諸表の専門家である公認会計士が適正と認めるもの」です。内容 として監査を担当した会計士の名前や監査意見、その根拠などが書いてあります。そのた め、世の中に提出されたすべての有価証券報告書に対しこの監査報告書は添付されてい ます。 また提出本文書と違う点として、連結と個別で書類ごと分かれています。 以下が EDIENTで見たときの監査報告書です。上部のタブから「監査報告書」を選択 すると閲覧できます。監査報告書には連結と個別が別のファイルになっていることが確認 できます。
▲図 7.1 監査報告書の例（2023 年度トヨタ自動車株式会社）
74
7.2 監査報告書と KAMについて
7.2.2 KAMとは KAM（カム）は「監査上の主要な検討事項」（Key Audit Matters）の略称です。金融 庁によると KAMは以下のようなものだと言います。
監査人が実施した監査の透明性を向上させ監査報告書の情報価値を高めることにそ の意義がある。出典：金融庁　「監査上の主要な検討事項（KAM）の特徴的な事 例と記載のポイント」の公表
KAMは財務情報などと比べると参照されるケースは少ないですが、財務諸表の監査に おいて特に重要なことが書かれています。そのため、監査報告書の中では重要視されるこ とが多いです。また、企業・事業ごとで業務の体系・詳細は変わってくるため、それらを どう監査のルールに当てはめるのかなどが書かれています。他にも内容だけでなく、表の 見出しも企業や年度によっても異なるため、見出しの中にどんな単語が多いのかなど分析 ができるのが特徴です。
75
第 7章監査報告書から KAMを自動で取得しよう
▲図 7.2 KAM の例 1
76
7.3 監査報告書から KAMを自動で取得する
▲図 7.3 KAM の例 2
例）トヨタ自動車 2023年度の KAM
7.3 監査報告書から KAMを自動で取得する 監査報告書と KAMがどのようなものなのか分かったところで、実際にデータを取得し てみましょう。
7.3.1 タクソノミを確認しよう 本章でも情報を取得するために、タクソノミを確認します。 今回は 2章で紹介したタクソノミの参照方法の 3つ目である、「金融庁のタクソノミ要 素リスト」を使用してタクソノミを参照します。理由としては KAM は標準タクソノミ というどの有報にも必ず存在するタクソノミだからです。標準タクソノミは金融庁から提 出されているタクソノミ要素リストから確認することができます。タクソノミ要素リスト
77
第 7章監査報告書から KAMを自動で取得しよう
からの参照方法は、標準タクソノミを調べる際は一番見つかりやすい参照方法です。ただ し、情報が多すぎてどこを探したらいいのかわからなかったり、たまに間違ったりもする ため注意が必要です。 タクソノミ要素リストは以下の URLからダウンロードができます。 https://www.fsa.go.jp/search/20231211/1e_ElementList.xlsx （1）目次から「9 企業内容等の開示に関する内閣府令 第三号様式 有価証券報告書
(jpcrp03000-asr)」のシートを選択
▲図 7.4 タクソノミ要素リスト目次
（2）「Ctrl」＋「F」で検索窓から「監査上の主要な検討事項」と検索 （3）「詳細ツリー‐標準ラベル（日本語）」（B列）でヒットするものを探す
▲図 7.5 タクソノミ要素リスト内で検索
（4）「冗長ラベル（日本語）」（C列）で連結のものと個別のものが分かれていることが
78
7.3 監査報告書から KAMを自動で取得する
確認できるため連結のものの「要素名」（I列）を確認
▲図 7.6 タクソノミ要素リストから参照
これを keyとして使用します。 注意点として、連結と個別のファイルがそれぞれあります。連結の KAMを抽出したい ため、タグは"KeyAuditMattersConsolidatedTextBlock"です。 今回は今までとは異なり、タグが「：」で分かれていないため Excelファイルの I列目 である要素名だけ指定しましょう。
context_ref に関しては財務情報と異なり、当期のものしかないため"FilingDateIn-stant"と指定します。 以上の 2つをメモします。
7.3.2 取得するコードを書こう 大枠は前章までと変わりませんので、異なる点をメインに説明します。 KAMは有価証券報告書の提出本文書ではなく監査報告書にのみ記載されている内容の ため、有報のパスだけでなく、監査報告書のパスも通します。 今まで参照していた有報の中の提出本文書類を示すものが「PublicDoc」です。今回は 監査報告書の中からデータを取得したいため、パスを通すときに「AuditDoc」と指定し ます。
79
第 7章監査報告書から KAMを自動で取得しよう
▼表 7.1 書類種別 EDINETから見たときの名称 フォルダを開いたときの名称 提出本文書類 PublicDoc 監査報告書 AuditDoc
監査報告書の連結と個別の区別はファイル単位で分かれているため、正規表現を使用し ても正しくファイルを指定できるようにしていきます。
EDINET からダウンロードした監査報告書のファイル名には略号というものがあり、 これを活用していきます。
▼表 7.2 監査報告書 独立監査人の報告書 略号 基本的な会計のドメイン知識 監査報告書及び内部統制監査報告書 aai 連結の情報が載っている 監査報告書 aar 個別の情報が載っている
本章では、連結の情報を取得します。連結のデータが存在する「aai」のファイルを指定 します。
80
7.3 監査報告書から KAMを自動で取得する
▲図 7.7 タクソノミで連結・個別の指定をする
aaiがある場所は AuditDoc と .xbrl の間です。正規表現を用いてここに aaiが載って いるファイルを指定し過不足なくデータを取得できます。指定ができたら company_info に両方のファイルを入れます。 def main():
xbrl_files = glob.glob(r'* フォ ル ダ 名 \*\ XBRL\PublicDoc \*. xbrl') audit_files = glob.glob(r'* フォ ル ダ 名 \*\ XBRL\AuditDoc \*aai*.xbrl')
company_info = make_edinet_company_info_list(xbrl_files , audit_files)
ファイルを読み込む部分でも audit_files を読み込みます。zip を使用し、有報のデー タと監査報告書のデータが一組にします。 for index , (xbrl_file , audit_file) in enumerate(zip(xbrl_files , audit_files)):
company_data = { "EDINETCODE": "", "企 業 名 ": "", "KAM": "",
}
# (コ ン ト ロー ラー の 設 定 な ど は 省 略 )
model_xbrl = model_manager.load(xbrl_file) model_audit = model_manager.load(audit_file)
81
第 7章監査報告書から KAMを自動で取得しよう
EDIENTコードと企業名は有報から取得し、KAMは監査報告書から取得しています。 if文の中でタクソノミを指定します。KAMはテキストデータであるためデータクレン
ジングをします。 データは最後にリストで保管します。最後に保管せずに EDIENTコードと企業名を見 つけた段階でリストに入れてしまうと別のリストとして保管してしまいます。別のリスト で保管すると、企業名と KAMが別々になり思うように利用できないデータになってしま う可能性があります。 # 監 査 デー タ か ら KAMを 探 し て 取 得 for fact in model_audit.facts:
# KAMを 探 す if fact.concept.qname.localName == 'KeyAuditMattersConsolidatedTextBlock ':
if fact.contextID == 'FilingDateInstant ': company_data["KAM"] = fact.value
# BeautifulSoupを 使っ て HTMLタ グ を 除 去 soup = BeautifulSoup(company_data["KAM"], "html.parser") company_data["KAM"] = soup.get_text ()
# 空 白 や 改 行 を 取 り 除 く company_data["KAM"] = re.sub(r'\s', '', company_data["KAM"]).strip()
# 見 つ け た デー タ を リ ス ト に 入 れ る edinet_company_info_list.append ([
company_data["EDINETCODE"], company_data["企 業 名 "], company_data["KAM"],
])
以下がすべてをまとめたソースコードになります。
7.3.3 ソースコード from arelle import ModelManager from arelle import Cntlr import os import glob import re from bs4 import BeautifulSoup
def make_edinet_company_info_list(xbrl_files , audit_files): edinet_company_info_list = [] for index , (xbrl_file , audit_file) in enumerate(zip(xbrl_files , audit_files)):
company_data = { "EDINETCODE": "", "企 業 名 ": "", "KAM": "",
}
ctrl = Cntlr.Cntlr() model_manager = ModelManager.initialize(ctrl)
model_xbrl = model_manager.load(xbrl_file) model_audit = model_manager.load(audit_file) print("XBRL ファ イ ル を 読 み 込 ん で い ま す ", ":", index + 1, "/", len(
xbrl_files))
82
7.4 まとめ
# 実 デー タ を 探 し て 取 得 for fact in model_xbrl.facts:
# EDINET コー ド を 探 す if fact.concept.qname.localName == 'EDINETCodeDEI ':
company_data["EDINETCODE"] = fact.value
# 企 業 名 を 探 す elif fact.concept.qname.localName == 'FilerNameInJapaneseDEI ':
company_data["企 業 名 "] = fact.value
# 監 査 デー タ か ら KAMを 探 し て 取 得 for fact in model_audit.facts:
# KAMを 探 す if fact.concept.qname.localName == '
KeyAuditMattersConsolidatedTextBlock ': if fact.contextID == 'FilingDateInstant ':
company_data["KAM"] = fact.value
# BeautifulSoupを 使っ て HTMLタ グ を 除 去 soup = BeautifulSoup(company_data["KAM"], "html.parser") company_data["KAM"] = soup.get_text ()
# 空 白 や 改 行 を 取 り 除 く company_data["KAM"] = re.sub(r'\s', '', company_data["KAM"]).
strip()
# 見 つ け た デー タ を リ ス ト に 入 れ る edinet_company_info_list.append ([
company_data["EDINETCODE"], company_data["企 業 名 "], company_data["KAM"],
])
return edinet_company_info_list
def main(): xbrl_files = glob.glob(r'* フォ ル ダ 名 \*\ XBRL\PublicDoc \*. xbrl') audit_files = glob.glob(r'* フォ ル ダ 名 \*\ XBRL\\ AuditDoc \*aai*.xbrl')
company_info = make_edinet_company_info_list(xbrl_files , audit_files) for info in company_info:
print(info)
print("extract␣finish")
if __name__ == "__main__": main()
7.4 まとめ 本章では、監査報告書から KAMという監査をする上で注目した点などのデータを取得 しました。普段見ることが多くない書類・項目ではありますが取得が確認できました。 次章では今まで取得したデータを一つのコードでまとめて Excel形式で出力するという
ことをします。Excelで出力することによりターミナルで確認するよりも見やすく、二次 利用もしやすくなると思います。
83
第 8章
CSVファイルで出力しよう
8.1 本章の目的 本章では、前章までで集めた個々のデータをまとめて CSVファイルで出力する方法を 解説します。CSVファイルでデータ出力すれば、XBRLからデータを都度ダウンロード しなくても、Excelや Pythonなどを用いて EDINETから出力したデータを参照できる ようになります。 今回は、今まで取得してきたデータに「業種」を加えた以下の 6項目をカラムに設定し ます。
• EDINETコード
• 企業名
• 業種
• 営業利益 (IFRS)
• 事業等のリスク
• KAM
今回は EDIENT コードが小さい順になるように並び替えて出力しました。具体的に は、以下のようなイメージで出力します。
84
8.2 CSVファイルでデータを出力しよう
▲図 8.1 成果物イメージ
8.2 CSVファイルでデータを出力しよう 全体のコードが長いため、以前と異なる点について細かく解説します。
8.2.1 前回までに取得した項目をまとめる 前章までで取得できた項目を 1つのコードにまとめます。
# 実 デー タ を 探 し て 取 得 for fact in model_xbrl.facts:
# EDINET コー ド を 探 す if fact.concept.qname.localName == 'EDINETCodeDEI ':
company_data["EDINETCODE"] = fact.value
# 企 業 名 を 探 す elif fact.concept.qname.localName == 'FilerNameInJapaneseDEI ':
company_data["企 業 名 "] = fact.value
# 営 業 利 益 (IFRS)を 探 す elif fact.concept.qname.localName == 'OperatingProfitLossIFRS ':
if fact.contextID == 'CurrentYearDuration ': company_data["営 業 利 益 (IFRS)"] = fact.value
# 事 業 等 の リ ス ク を 探 す elif fact.concept.qname.localName == 'BusinessRisksTextBlock ':
if fact.contextID == 'FilingDateInstant ': raw_risk = fact.value # BeautifulSoupを 使っ て HTMLタ グ を 除 去 soup = BeautifulSoup(raw_risk , "html.parser") company_data["事 業 等 の リ ス ク "] = re.sub(r'\s', '', soup.get_text ()).
strip()
# 監 査 デー タ か ら KAMを 探 し て 取 得 for fact in model_audit.facts:
if fact.concept.qname.localName == 'KeyAuditMattersConsolidatedTextBlock ': if fact.contextID == 'FilingDateInstant ':
raw_kam = fact.value # BeautifulSoupを 使っ て HTMLタ グ を 除 去 soup = BeautifulSoup(raw_kam , "html.parser") company_data["KAM"] = re.sub(r'\s', '', soup.get_text ()).strip()
85
第 8章 CSVファイルで出力しよう
# 見 つ け た デー タ を リ ス ト に 入 れ る edinet_company_info_list.append(list(company_data.values ()))
8.2.2 業種のデータを取得する 次に業種のデータを取得します。有報の中には業種のデータが存在しないため、
EDINET が用意した EDINET コードリストを用います。EDINET コードリストの 中には EDINETコードと業種のデータが紐づいています。それを利用して業種データを 取得します。
EDIENTのホーム画面より上部のタブから「EDIENTタクソノミ及びコードリスト　 ダウンロード」という一番右のタブを開きます。
▲図 8.2 EDINET から EDINET コードリストを参照する
ページの一番下にある「EDIENTコードリスト」の CSVファイルをダウンロードし、 ディレクトリの中に入れます。
86
8.2 CSVファイルでデータを出力しよう
▲図 8.3 EDINET コードリストをダウンロードする
次に EDIENTコードリストを参照できるようにパスを通します。 def main():
# EDINET コー ド リ ス ト を 追 加 edinetcodedlinfo_filepath = r'C:\ Users\ ユー ザー 名 \Downloads\
Edinetcode_20241007\EdinetcodeDlInfo.csv' edinet_info_list = make_edinet_info_list(edinetcodedlinfo_filepath)
# (こ こ に 有 報 と 監 査 報 告 書 の XBRL ファ イ ル の パ ス を 指 定 )
edinet_company_info_list = make_edinet_company_info_list(xbrl_files , edinet_info_list , audit_files)
データを探すコードで EDINETコードを取得する部分に業種を取得するコードを付け 足します。 # EDINET コー ド を 探 す if fact.concept.qname.localName == 'EDINETCodeDEI ':
company_data["EDINETCODE"] = fact.value
# 業 種 を EDINET コー ド に 基 づ い て 設 定 for code_name in edinet_info_list:
if code_name [0] == company_data["EDINETCODE"]: company_data["業 種 "] = code_name [1] break
さらに EDINETコードと業種のデータを紐づける関数を作成します。 def make_edinet_info_list(edinetcodedlinfo_filepath):
edinet_info = pd.read_csv(edinetcodedlinfo_filepath , skiprows=1, encoding= 'cp932 ')
edinet_info = edinet_info [["Ｅ Ｄ Ｉ Ｎ Ｅ Ｔ コー ド ", "提 出 者 業 種 "]] edinet_info_list = edinet_info.values.tolist () return edinet_info_list
以上で業種のデータを取得出来るようになりました。
87
第 8章 CSVファイルで出力しよう
8.2.3 CSVで出力する write_csv() 関数を作り、CSV ファイルで出力します。CSV で出力するためには
Pandas という Python のライブラリを使います。Pandas はデータフレームという二次 元表の形にするときに使うライブラリです。インポートのところに Pandas を追加しま す。Pandas はデータフレームというリストをテーブル形式に落とし込むライブラリで す。データフレームのカラムに初めに決めた 6項目を設定します。 次に今回は EDINET コードが小さい順にソートし、encoding を指定して文字化けを
防ぎます。今回は BOM 付きの UTF-8 である「UTF-8-sig」を指定しました。最後に 「xbrl_book.csv」というファイル名で出力します。 # イ ン ポー ト import pandas as pd
def write_csv(edinet_company_info_list): xbrl_frame = pd.DataFrame(edinet_company_info_list ,
columns =['EDINETCODE ', '企 業 名 ', '業 種 ', '営 業 利 益 (IFRS)( 円 )', '事 業 等 の リ ス ク ', 'KAM'])
# EDINET コー ド で ソー ト xbrl_frame_sorted = xbrl_frame.sort_values(by='EDINETCODE ', ascending=True
)
# CSV ファ イ ル で 出 力 xbrl_frame_sorted.to_csv("xbrl_book.csv", encoding='utf -8-sig', index=
False)
これで CSVファイルに出力することができます。
8.2.4 エラーハンドリングを追加 最後にエラーハンドリングを追加します。エラーハンドリングとは、どこで何のエラー が起きているのかわかるようにしておくことです。エラーハンドリングを追加しておく と、コード自体に問題があるのかデータ自体に問題があるのか、またどういったところを 修正すればいいのかなどがわかります。様々な処理をするコードを書く場合はエラーハン ドリングを追加することは必須となってきます。 try:
(処 理 ) except Exception as e:
print(f"処 理 中 に エ ラー が 発 生 し ま し た :{e}")
これを以下の処理すべてのところに書きます。ソースコードを参考に追記して下さい。
• EDINETコードと業種を紐づける処理
• XBRLファイルを読み込む処理
88
8.2 CSVファイルでデータを出力しよう
• 有報を解析する処理
• 監査報告書を解析する処理
• CSVを書き込む処理
8.2.5 ソースコード from arelle import ModelManager from arelle import Cntlr import os import glob import re from bs4 import BeautifulSoup import pandas as pd
def make_edinet_info_list(edinetcodedlinfo_filepath): try:
edinet_info = pd.read_csv(edinetcodedlinfo_filepath , skiprows=1, encoding= 'cp932 ')
edinet_info = edinet_info [["Ｅ Ｄ Ｉ Ｎ Ｅ Ｔ コー ド ", "提 出 者 業 種 "]] edinet_info_list = edinet_info.values.tolist () return edinet_info_list
except Exception as e: print(f"EDINET情 報 の 取 得 に 失 敗 し ま し た :␣{e}") return []
def make_edinet_company_info_list(xbrl_files , edinet_info_list , audit_files): edinet_company_info_list = [] for index , (xbrl_file , audit_file) in enumerate(zip(xbrl_files , audit_files)):
company_data = { "EDINETCODE": None , "企 業 名 ": None , "業 種 ": None , "営 業 利 益 (IFRS)": None , "事 業 等 の リ ス ク ": None , "KAM": None ,
}
try: ctrl = Cntlr.Cntlr() model_manager = ModelManager.initialize(ctrl) model_xbrl = model_manager.load(xbrl_file) model_audit = model_manager.load(audit_file) print("XBRL ファ イ ル を 読 み 込 ん で い ま す ", ":", index + 1, "/", len(
xbrl_files))
except Exception as e: print(f"XBRL ファ イ ル の 読 み 込 み に 失 敗 し ま し た ␣({ xbrl_file}␣ま た は ␣{
audit_file }):␣{e}") edinet_company_info_list.append(list(company_data.values ())) continue
try: # 実 デー タ を 探 し て 取 得 for fact in model_xbrl.facts:
# EDINET コー ド を 探 す if fact.concept.qname.localName == 'EDINETCodeDEI ':
company_data["EDINETCODE"] = fact.value
# 業 種 を EDINET コー ド に 基 づ い て 設 定 for code_name in edinet_info_list:
89
第 8章 CSVファイルで出力しよう
if code_name [0] == company_data["EDINETCODE"]: company_data["業 種 "] = code_name [1] break
# 企 業 名 を 探 す elif fact.concept.qname.localName == 'FilerNameInJapaneseDEI ':
company_data["企 業 名 "] = fact.value
# 営 業 利 益 (IFRS)を 探 す elif fact.concept.qname.localName == 'OperatingProfitLossIFRS ':
if fact.contextID == 'CurrentYearDuration ': company_data["営 業 利 益 (IFRS)"] = fact.value
# 事 業 等 の リ ス ク を 探 す elif fact.concept.qname.localName == 'BusinessRisksTextBlock ':
if fact.contextID == 'FilingDateInstant ': raw_risk = fact.value # BeautifulSoupを 使っ て HTMLタ グ を 除 去 soup = BeautifulSoup(raw_risk , "html.parser") company_data["事 業 等 の リ ス ク "] = re.sub(r'\s', '', soup.
get_text ()).strip()
except Exception as e: print(f"有 報 の 解 析 中 に エ ラー が 発 生 し ま し た ␣({ xbrl_file }):␣{e}")
try: # 監 査 デー タ か ら KAMを 探 し て 取 得 for fact in model_audit.facts:
if fact.concept.qname.localName == ' KeyAuditMattersConsolidatedTextBlock ':
if fact.contextID == 'FilingDateInstant ': raw_kam = fact.value # BeautifulSoupを 使っ て HTMLタ グ を 除 去 soup = BeautifulSoup(raw_kam , "html.parser") company_data["KAM"] = re.sub(r'\s', '', soup.get_text ()).
strip()
except Exception as e: print(f"監 査 報 告 書 の 解 析 中 に エ ラー が 発 生 し ま し た ␣({ audit_file }):␣{e}")
# 見 つ け た デー タ を リ ス ト に 入 れ る edinet_company_info_list.append(list(company_data.values ()))
return edinet_company_info_list
def write_csv(edinet_company_info_list): try:
xbrl_frame = pd.DataFrame(edinet_company_info_list , columns =['EDINETCODE ', '企 業 名 ', '業 種 ', '営 業 利 益 (IFRS)(
円 )', '事 業 等 の リ ス ク ', 'KAM'])
# EDINET コー ド で ソー ト xbrl_frame_sorted = xbrl_frame.sort_values(by='EDINETCODE ', ascending=True
)
# CSV ファ イ ル で 出 力 す る xbrl_frame_sorted.to_csv("xbrl_book.csv", encoding='utf -8-sig', index=
False) except Exception as e:
print(f"CSVの 書 き 込 み 中 に エ ラー が 発 生 し ま し た :␣{e}")
def main(): # EDINET コー ド リ ス ト を 追 加 edinetcodedlinfo_filepath = r'C:\ Users\ ユー ザー 名 \Downloads\
Edinetcode_20241007\EdinetcodeDlInfo.csv' edinet_info_list = make_edinet_info_list(edinetcodedlinfo_filepath)
90
8.3 まとめ
xbrl_files = glob.glob(r'*xbrl_zip \*\ XBRL\PublicDoc \*. xbrl') audit_files = glob.glob(r'*xbrl_zip \*\ XBRL\AuditDoc \*aai*.xbrl')
edinet_company_info_list = make_edinet_company_info_list(xbrl_files , edinet_info_list , audit_files)
write_csv(edinet_company_info_list) print("extract␣finish")
if __name__ == "__main__": main()
8.3 まとめ 本章では、XBRLを用いて欲しい情報を CSVファイルで出力することについて解説し
ました。XBRLを用いることでコピペ間違いなどを防止できます。また、CSVファイル での出力は見やすいだけでなく、二次利用にも適しています。
91
第 9章
おわりに
最後まで本書を読んで頂き誠にありがとうございました。本書は、著者一同が所属して いる合同会社オントロジーにおける XBRL解説記事の連載をベースに、書籍用に加筆修 正したものです。XBRL は国際規格であるにもかかわらず、非常に理解している人が少 ない（いたとしても、宝印刷やプロネクサスのような印刷会社の開発者、アセットマネジ メントの会社に勤務しているクオンツ、東京証券取引所に勤務しているエンジニアといっ た専門職くらいしかいない）のが現状です。そのため、現状にに危機感を持った XBRL JAPAN(日本の XBRL普及のために活動している団体)が「プラティカル XBRL」とい う XBRLの勉強会といった啓蒙活動を行っているなど、業界として盛り上げていかねば ならない状況になっております。本書は、XBRLのユーザーがすこしでも増えるように、 「とりあえず動かせるようになる」を第一目標にハードルを下げるために書籍を執筆しま した。少しでも興味を持って頂いたうえで、XBRL解析の本当に辛い所（タグの中身に文 句行ったり、XMLを理解したり、オレオレパーサーを作成したり）といった深淵に触れ るきっかけになってほしいです（ここが一番苦しいのですが、この辺りまだ体系化出来て いないので、ユーザーを増やして意見をガンガン集めていきたい・・・）。
92
付録 A
Arelle以外のパーサーの紹介
XBRL を解析できるライブラリは Arelle 以外も存在します。ここで紹介するのは edinet-xbrl というライブラリです。Arelle と edinet-xbrl には以下のような違いがあり ます。
▼表 A.1 パーサーごとの違い
メリット デメリット Arelle XBRL 公式からのお墨付きがあり定
期的にメンテナンスされていて、安心 して使用できる
コードが少し複雑で理解しづらい
edinet-xbrl コードがシンプルで見やすい メンテナンスが約 5 年間されておら ず、データ抽出できなくなる危険性が ある
表が pdfにするとはみでるので、折り返すように対策をしてほしい その他にも、個人で XBRL解析機を作成し使用している方もいます。これらの XBRL
解析機は元をたどれば lxmlという XMLを解析するためのライブラリで情報を抽出して います。このライブラリではインスタンス情報やタグ部分の情報を抽出するなどできるこ とが非常に多くあるため、「自分の取得したい値だけを抽出する解析機」か「全ての情報 を抽出できる解析機」かを決める必要があります。ただし、XBRL は複数の XML ファ イルと情報を連携させ成り立っており、これら XBRLを含める xmlを読み解くことは非 常に大変な作業です。ここまでの情報を踏まえて、自分にあった解析機の使用が望ましい です。
93
付録 B
pathとは何か
通常 PCではファイルやフォルダがツリー上の階層構造になっており、この階層のこと をディレクトリといいます。path(パス) というのは PC 内でディレクトリの場所を文字 列で表したものです。パスには絶対パスと相対パスという 2種類があります。それぞれ以 下のような違いがあります。 絶対パス：全てのディレクトリの頂点に当たる場所から、目的のファイルやフォルダま での道のりを「/」で区切って表現する。 相対パス：プログラムを作成するにはユーザーはいずれもどこかのディレクトリを作業 場所にしている。その作業場から見ての目的のファイルやフォルダまでの道のりを「/」 を区切って表現する。 「/」と「￥」は PC内で同じ意味で解釈されていることに注意してください。
▲図 B.1 パスの例
94
付録 C
テキストデータの注意点
XBRLの仕様上、テキストデータの扱いにはいくつか注意点が存在します。 1つ目は、取得箇所についてです。XBRLからテキストデータを取得したとき、より大
きな区分でしかデータを取得できないといったケースがあります。導入部分が含まれた状 態での取得や企業が提示している細かな内容の取得ができないといったケースです。
2つ目は、見出しについてです。テキストデータでは XBRLの構造上、見出しもデー タに含まれます。取得情報に間違いが少ない一方で、分析の時には弊害にもなり得ます。 これらのケースを考慮して分析を行うか、データ取得時に取り除く処理をする必要があり ます。
3つ目は、空白や改行についてです。テキスト分析をするときには文章を単語ごとに区 切り、分析を行います。「単語の使用数」や「単語の特徴」などを確認していくことで、最 終的に文章の傾向や特徴を分析できます。空白や改行はそれらを 1つの単語として認識さ れるため、分析に影響を及ぼす危険性があります。本章では HTMLタグや空白・改行の 除去を行うことで対処しました。
95
付録 D
コラム：フィルタリングしてダウン ロードのできるできない
EDINET API の書類取得 API には取得する書類の種類を指定することができると解 説しました。その機能を活かすとフィルタリングしてデータをダウンロードできます。で きる項目とできない項目があるので以下にまとめました。
D.0.1 簡単にできる
• 提出日
そもそも書類一覧 APIが日付ごとに取得するものなので、必須の位置づけです。
D.0.2 できる
• 提出者名/ファンド
• 提出書類の種類
• 投資信託であるかどうか
D.0.3 できない
• 業種
• 会社の規模
• 資本の大きさ
• 従業員数
• 企業年数
96
• 株式の保有数
これらは書類一覧 APIで取れるメタデータに含まれるかどうかに依存するため、この ように分類になっています。
97
付録 E
ライブラリとは何か
本書において、プログラムを用いたコードの実践を行いました。その中で、コードの開 始の部分に import reのような記載がされることがあります。この箇所では、ライブラ リのインポートをしています。 ライブラリとは、特定のタスクやプロジェクトに関連する便利な機能をまとめたもので す。ライブラリは主に標準ライブラリと外部ライブラリに分類されます。標準ライブラリ は Pythonで公式に用意されたもので、datetimeモジュールや osモジュールなどです。 それに対して、外部ライブラリは別の組織か個人が用意したもので、pandasや numpyな どです。多くは複数のモジュールがまとめられパッケージで提供されています。 多くは複数のモジュールがまとめられパッケージで提供されています。これらは
「import 〇〇」と記述することでコード内で使用することができ、外部ライブラリを使 用する際はこの前に「pip install 〇〇」とターミナルにコマンドを入力し、PCにインス トールします。ライブラリを使用することで、すでに開発された安全で質の高いプログラ ムを利用し、より効率的にプログラムが作成出来ます。 # モ ジュー ル を 利 用 す る た め の コー ド import numpy as np
# ラ イ ブ ラ リ を イ ン ス トー ル す る た め の コー ド pip install lightgbm
98
付録 F
会計基準が違うとなぜ同時にデータ 取得ができないの？
本書では「国際会計基準 (IFRS)で作成された連結の財務諸表から営業利益の額」とい う条件のもとデータを取得しました。ここまで条件を指定しなくてはデータ取得ができな い理由は、会計基準というそもそものルールが異なるからです。日本の企業が財務諸表を 作成する場合、従来からの日本会計基準に則って作成される場合と各国の異なるルールを 一般化しようとする国際会計基準に則って作成する場合が混在しています。さらに、グ ループ会社など組織全体についてが記載されている連結財務諸表と、グループがあったと してもその企業についてのみ記載されている個別財務諸表があり、連結と個別で採用して いる会計基準が異なることさえあります。同じ財務諸表とはいえ、ルールや対象が異なる もの同士ではタクソノミも異なるため、同時に取得することは不可能です。
99
付録G
有価証券報告書以外の書類の集め方
本書では、有価証券報告書をまとめてダウンロードしましたが、有価証券報告書以外の書 類を自動でダウンロードすることもできます。その際には、ordinate_code, form_code を変更します。 有価証券報告書を集めたい場合には、ordinance_code == 010, form_code == 030000 を指定しました。 以下の表であるようにほかの一般的な EDINETの書類は以下のような組み合わせで取 得できます。
▼表 G.1 その他の書類 書類名 ordinance_code form_code 四半期報告書 010 043000 半期報告書 010 050000 訂正有価証券報告書 010 030001
ordinance_code は内閣府令を意味し、form_code は内閣府令の何号様式かを意味し ます。
EDINET API仕様書 (version2)を参照して、内閣府令に対応した ordinance_codeを 選択します。また、タクソノミ要素リストを参照して、内閣府令の何号様式化に対応した form_codeを選択します。 以上を適切に施託することで有価証券報告書以外の書類もダウンロードすることができ ます。
100
▲図 G.1 内閣府令コード
引用：EDINET API仕様書（version2）p85
▲図 G.2 form コード
引用：https://www.fsa.go.jp/search/20231211.htmlよりタクソノミ要素リスト.xlsx 書類が異なれば記述される内容も異なります。同じようにタクソノミも異なるため、注 意が必要です。
101
著者紹介
稲垣大輔 / @kabanyasu 稲垣大輔公認会計士税理士事務所・合同会社オントロジー代表 公認会計士・税理士・システム監査技術者 システムのわかる公認会計士として、Python によるデータ解析や XBRL を用いた分 析等に携わる。 現在は税理士業務・決算体制構築支援・システム監査・IT統制構築支援に携わる。 代表作に『Pythonではじめる会計データサイエンス』（中央経済社）がある。
成木涼雨 合同会社オントロジーインターンの大学 4年生 ダンスサークルの長をやっていた陽キャであるが実はアニメ好き（好きなアニメは天元 突破グレンラガン）
Pythonや XBRLを用いた意思決定支援等に従事
井原侑哉 合同会社オントロジーインターンの大学 3年生 元ラガーマンであるがその気配を一向に見せない。 Pythonや XBRLを用いた意思決定支援等に従事
102
103
Pythonで学ぶXBRL入門
2024年 10月 23日　発行
著　者 稲垣大輔、井原侑哉、成木涼雨 　
(C) 2020-2024 Onto-logy.com
104
XBRL入門 Python 学ぶで